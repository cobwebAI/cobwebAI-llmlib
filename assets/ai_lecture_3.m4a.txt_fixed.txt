OUTPUT_TITLE: Введение в нейронные сети: основы архитектуры, обучения и функций активации 

 Все, запись начала, отлично, теперь точно можно начинать. Так вот, быстро повторюсь, мы сегодня с вами говорим про нейронные сети и наконец-то переходим к ним. Начнем с самых простых объектов архитектуры нейронных сетей, то есть с модели перцептрона. Из перцептронов мы будем строить с вами многослойные нейронные сети. Мы говорили про постановку задач машинного обучения с учителем, и я напомню, что у нас есть данные x и ответ к ним y. Например, это может быть задача с квартирами: у нас каждый объект — это квартира, у которой есть признаки, и ответы — это цена. Наша задача — предсказать цену, то есть у нас есть x, у каждого x есть признаки x1, x2, x3 и так далее, и есть y. Задачи машинного обучения строятся так, что мы подбираем алгоритм A, чтобы получать отображение из x к y. Понимаем, что невозможно на всех данных сделать абсолютно точное отображение, поэтому вводим loss-функцию, которая показывает, насколько близко мы приближаемся к ответам — это функция ошибки. Задача сводится к тому, что нам нужно минимизировать эту функцию ошибки, изменяя параметры модели.

Кстати, сейчас я посмотрю, видно ли, а то вдруг я закрываю немного камеру. Вы же демонстрируете, Петров. Да, я понимаю, но давайте продолжим. Окей, соответственно, мы успели поговорить про линейные модели. Формула для линейной модели выглядит как матричная запись. Я напоминаю, что мы пользуемся матричными операциями, и вы сегодня увидите, почему именно они. Функции для задачи регрессии — это MSE и MAE. Мы говорили, как они выглядят, что они делают, и как это делается с помощью градиентного спуска. Чтобы посчитать градиентный спуск, нам нужно посчитать градиент, и мы обсуждали, что линейная регрессия выглядит таким образом.

Также мы говорили про задачу классификации, в частности, бинарной классификации. В классификации задача выглядит иначе: нам нужно выделить прямую, которая разделяет объекты на два класса. Для этого вводим функцию активации, на вход которой подаем линейную комбинацию данных. Предсказаниями тогда Y будет функция, зависящая от этой линейной комбинации. У нас появляется посредственная переменная Z, являющаяся этой линейной комбинацией. Класс функции для логистической регрессии выглядит так, что значения будут от 0 до 1. Сигмоида стремится к нулю или к единице. В этом случае, если значение 0, то результат обнуляется.

Во всех классах функций я напомню, что мы усредняем по всем объектам из датасета. Везде стоит сумма по всем объектам из датасета. Это то, что было в прошлый раз. Теперь будем строить нейронные сети. Рассмотрим, откуда берутся нейронные сети и почему они стали столь популярны. Первые модели нейронных сетей появились еще в 20 веке, но были в основном теоретическими. Для обучения нейронных сетей нужны были данные и вычислительные мощности, которые в тот момент отсутствовали. В 90-х, когда компьютеры стали развиваться, все еще была проблема с хранением данных.

С началом 2000-х годов произошел скачок с появлением видеокарт. Именно тогда искусственный интеллект получил популярность, особенно в задачах распознавания образов. Сеть AlexNet в корне изменила ситуацию: она обошла классические алгоритмы компьютерного зрения по всем метрикам. Люди поняли, что чем больше данных мы подаем, тем лучше работает нейронная сеть. А классические алгоритмы машинного обучения достигают определенного плато по качеству. Нейронные сети, же, продолжают улучшаться, если их обучать на больших объемах данных.

В общем, нейронные сети обладают меньшими ограничениями в качественных характеристиках, и это позволяет им добиваться все более впечатляющих результатов. Когда в 2000-х годах появились видеокарты, это создало возможность обучать их на больших данных, и нейронные сети начали набирать популярность. Нейронные сети могут лучше справляться с задачами, когда данные имеют нелинейные зависимости. Если возникает нелинейная зависимость, линейная модель не будет работать хорошо.

Таким образом, когда вы сталкиваетесь с задачей классификации, вам нужно применять нейронные сети, чтобы найти те сложные зависимости, которые линейные модели не могут уловить. В следующем семестре вы изучите методы, которые помогут в этой задаче, такие как методы ближайших соседей и градиентный бустинг. Но нейронные сети, если их хорошо обучить, могут более точно справляться с задачами.

В чисто математическом плане доказано, что любой непрерывной функции можно аппроксимировать с помощью нейронной сети. Нейронная сеть состоит из входного слоя, промежуточных слоев и выходного слоя, где каждый сигнал идет к каждому нейрону. Входные сигналы — это наши данные или признаки, и мы суммируем их с некоторыми весами, создавая линейную комбинацию. Это соответствует линейной модели. А вот дальше ключевой момент – это то, что мы применяем нелинейность, то есть это называется функция активации. Функция активации – это какая-то нелинейная функция. Мы сейчас с вами посмотрим, какие бывают. Но суть в том, что именно эта нелинейность позволяет нам аппроксимировать нелинейные зависимости. Давайте теперь посмотрим, какие функции активации бывают. Мы уже видели, что логистическая регрессия применяется с сигмоидой, но на самом деле есть много разных функций активации. 

Есть гиперболический тангенс, который изменяется от минус одного до одного. Также существует функция активации ReLU. Ее суть в том, что при отрицательных значениях она принимает значение 0, а при положительных равна просто x, то есть это прямая под углом 45 градусов. Мы обсуждали, что у ReLU есть две проблемы. Во-первых, в нуле есть резкий излом, и теоретически может возникнуть проблема со взятием производных, но на практике этой проблемы обычно не бывает. Еще одна проблема в том, что при отрицательных значениях вы обрезаете много сигналов, так как если они поступают на вход нейрона как отрицательные, они просто обнуляются. Если вам не хочется обнулять их, можно применять модифицированную ReLU, так называемую Leaky ReLU, где при отрицательных значениях сигнал не равен 0, а другим значением под другим углом.

Существует множество других функций активации, например, ELU. Но самые основные, которые чаще всего применяются в нейронных сетях – это ReLU и сигмоида. Гиперболический тангенс тоже используется. В принципе, любой из них можно применять и смотреть, что у вас получается. Сейчас я попробую запустить следующую часть.

Давайте посмотрим, как сигнал распространяется в нейронных сетях. Вопрос на засыпку: что будет, если у нас не будет функции активации? Если мы просто суммируем все сигналы, получится просто линейная функция. Даже если у вас много нейронов, но функция активации будет отсутствовать, все линейные комбинации останутся линейными. Функция активации – это ключевой элемент, который позволяет нам делать аппроксимацию нелинейных зависимостей.

Теперь о градиентном спуске. Логистическая регрессия была линейной комбинацией, к которой применялась сигмоида. В нейронной сети могут быть множество нейронов. Если в логистической регрессии у нас был один выходной сигнал, то в многослойной нейронной сети у нас может быть много слоев и много нейронов на каждом слое.

Вам нужно представлять, что сигналы из входного слоя передаются на выходной слой через множество нейронов. Например, в задаче классификации может потребоваться иметь несколько выходов. Примером может быть классификация изображений, как в наборе данных ImageNet, где есть 1000 классов.

Теперь давайте рассмотрим прямое распространение в нейронной сети более подробно. У нас есть некий слой, и нам нужно посчитать выходы на основе значений, которые находятся в этом слое. Сначала мы домножаем веса на значения из этого слоя и прибавляем смещение. Обратите внимание, что здесь V – это матрица весов. Количество строк в матрице будет равным количеству нейронов, а количество столбцов – количеству связей со следующим слоем.

Таким образом, в нейронных сетях становится видно, как работает матричная операция, где веса будут разными для каждого нейрона. Каждый нейрон передает разные веса на выходной слой, что подбирается в процессе обучения. Теперь вернемся к нашей матричной записи и попробуем расшифровать, что здесь происходит. Понятно. Может быть, потому что он переходит в этот нейрон? Не, в плане, почему \( v_1 \), это… Давайте сейчас, во-первых… Во-первых, \( x \) — это вот это желтое, да? Это все в целом… Да, \( x \) — это все желтые значения. \( x \) — это \( x \). Значит, дальше, этот \( x \) с какими-то весами \( b_0 \). Обратите внимание, \( b_0 \) плюс означает, что \( b_0 \) задействует все веса, которые находятся на этих линиях. И плюс некий \( b_0 \) тоже как бы задействует все векторы сразу. То есть это матричная запись, получается, и \( f_0 \), это некая функция активации, применяется здесь, и получается, что на выходе из этого мы получаем значение для этого слоя, для слоя 1. Дальше, соответственно, мы используем значение этого слоя, чтобы получить значение для следующего слоя. И получается, что для того, чтобы посчитать значение этого слоя, мы значение этого слоя теперь домножаем на матрицу \( b_1 \), и получается, что \( b_1 \) учитывает все веса, которые здесь. Вот. И для применения \( f_1 \) получаем значение здесь. Теперь дальше, чтобы получить значение для следующего слоя, мы значения, которые получились здесь, домножаем на \( b_2 \), то есть \( b_2 \) учитывает все, что здесь. И получаем, соответственно, значение здесь. В итоге мы получаем то, что здесь. Ну и, наконец, мы домножаем на \( b_3 \) выхода из этого слоя и получаем конечное значение. То есть получается, что \( b_3 \) учитывает все нейроны, которые здесь. И в итоге, если сделать все это, мы получаем выходные значения.

Теперь обратите внимание, что это математическая запись. Я хотел подробно вам это рассказать, потому что, например, чтобы получить \( 2.2 \), вам нужны значения, которые идут откуда-то… То есть, чтобы получить значение, например, скрытого слоя 2, вам нужны значения скрытого слоя 1, которые, в свою очередь, получаются из значений предыдущих слоев. Это как матрешка; чем дальше идем, тем больше запись возрастает. Но в корне этой записи лежит простая вещь. Вы просто используете значение предыдущего слоя, а чтобы посчитать этот слой, вы используете значение еще более предыдущего слоя. В итоге, чтобы получить значение на выходе, вы используете все эти связи, все слои и так далее. Вот эта запись — это все это. Просто \( F \) — это функция активации? Да, везде это функция активации. Здесь это может применяться на выходе. На самом деле, если \( F_0 \), \( F_1 \) и \( F_2 \) могут быть ReLU, то для \( F_3 \) можно применить Softmax. 

Почему мы используем матрицу? Да, на выходе получается… Да, четыре выхода. Можно конкретно, допустим, смотрите, сколько можно сделать. Я сразу пытаюсь вспомнить, как это реализовано в библиотеках. Там, по-моему, там зеленые выходы. Да, то есть четыре значения, они затем используются в любой расчетной функции. Вы можете взять какое-то конкретное значение и… Например, на выходе, что можно взять? Смотреть самый большой вес, и значит… Смотреть самый большой вес, значит… Ну, там, кошка. Да, смотрите, это было, вы смотрите значение, которое здесь, и наибольшее значение будет соответствовать классу, который предсказывает нейронная сеть. Это вы на семинаре увидите.

Короче говоря… Да, это правильно, что вы говорите. Поэтому… В плане, что на выходе получится, зависит от того, что у вас будет в качестве \( V_3 \) и так далее. Если на выходе… Если у \( V_3 \) размерность будет 4, то вы получите 4 значения. Правильно? Да, правильно. Окей. Таким образом, будет своя матрица весов, своя… Функция активации зависит от того, как вы зададите. Обычно в рамках одного слоя задают одну и ту же функцию активации, но для разных слоев можно использовать разные принципы. Нельзя, но обычно так не делают. Почему так не делают? Потому что вам нужно будет делать обратное распространение ошибки, и чем сложнее вы это будете задавать, тем сложнее будет считать градиенты. Чаще всего избегают усложнений.

По-хорошему, на картинке между слоями нужно нарисовать еще полукруги. Тут везде зашита функция активации. На выходе из каждого слоя, грубо говоря, есть нелинейность этого слоя. То есть это матричная запись так называемого inference. Что такое inference? У вас есть на входе \( x \), и вы их распространяете, чтобы получить выходные значения. Это, получается, распространение сигнала слева направо. Представьте, что вы уже обучили нейронную сеть. Если на вход приходит \( x \), чтобы получить выходные значения, вам нужно выполнить такие математические операции. По сути, работа нейронок — это просто перемножение матриц между собой с математической точки зрения. 

Теперь давайте, собственно, посмотрим, как их обучать. Для этого расскажу… Да, сейчас получится. Если вопросы есть в чате, тоже задавайте. Напишите там «плюс», если все нормально. Да, все плюс. Хорошо, спасибо. Сейчас проект отключится, и я продолжу. Итак, теперь мы с вами будем говорить про обучение. Напомните, как мы уже умеем обучать модели машинного обучения. Какой метод мы рассмотрели? Что нужно сделать, чтобы обучить модель машинного обучения? Ну, для этого нужны данные и результаты ответов. Дальше, что мы делаем? У нас есть ответы и выходы модели. Что с этим можно сделать? Считать ошибки. Далее считаем ошибки и минимизируем. А как минимизируем? Я это все говорю потому, что для нейронов остается все то же самое. У вас уже знакомая формула. 

Мы для каждого веса… То есть, представьте, у вас здесь куча весов над каждой линией. Вам нужно совершить такую операцию. Чтобы ее совершить, нужно посчитать производную. Причем много производных. Чем глубже нейронка, тем больше вычислений. Это логично. Потому что, как я вам говорил, чтобы посчитать производную по \( V_0\), вам нужно начать считать снаружи и внутрь. Аналитически это делается не очень удобно, особенно в глубокой нейронной сети. Поэтому придумали лайфхак — я говорил о нем на первой лекции. Он лежит в основе нейронных сетей. В частности, метод, который разработал Джеффри Хинтон, который получил Нобелевскую премию по физике в этом году. 

Суть в том, что сначала строим граф вычислений. Это не связано с этой картинкой, просто математическая абстракция, чтобы объяснить суть метода. Представьте, что хотите обновить веса. У вас есть какая-то сложная функция, например, чтобы получить выход, у вас есть несколько входов. Представьте, \( y = x_1v_1 \), и это навешивается на сигнал. Далее сюда приходит сигнал от \( x_1 \) и \( x_2 \), и они все агрегируются, и далее мы получаем некий выход. Чтобы посчитать производные, можно воспользоваться лайфхаком. 

Мы вводим промежуточные переменные, например, \( u_1, u_2 \). Чтобы посчитать производные по \( u_1 \), нам нужно отследить путь от выхода. Мы видим, что идем справа налево, отслеживаем путь и смотрим какие у нас функции у нас на этом пути. Если у нас возникла сигмоида, значит, у нас будет производная: \( \frac{dL}{d\sigma} \). Далее берем производную  сигмоиды по \( u \). И, наконец, последняя производная получается \( \frac{d\sigma}{d u_1} \). И чтобы посчитать эту производную, надо применить метод сложных функций: перемножить все частные производные. Получается, чтобы посчитать производную выходной функции по \( d \) переменной, нужно построить граф, посмотреть путь обратного распространения сигнала и взять все частные производные на пути, перемножить их. 

Этот метод называется chain rule, или метод обратного распространения ошибки. Значит, обучение нейронной сети выглядит так: сначала нужно посчитать выходную функцию, и чтобы посчитать сложную функцию, сигнал распространяется слева направо. Как только получите выходной сигнал, можете посчитать сложную функцию. После ее вычисления снова идете обратно, берете производные и умножаете их. И как только получили какой-то градиент, применяете его при методе градиентного спуска. Получается, каждый слой может делать свой градиентный спуск. Как только появляется градиент, сразу применяете градиентный спуск. Вот в этом и заключается метод — backpropagation. Почему backpropagation? Потому что вы считаете ошибку и выполняете вычисления справа налево. Сигнал как будто идет обратно, но вы просто считаете все производные. 

Теперь я покажу, как это можно еще раз посмотреть. Я повторяю, что в этой лекции много важных моментов. В такие случаи всегда что-то пропускаю, но тем не менее. Чтобы обучить нейронку, сначала нужно выполнить forward, а потом backward. Вот здесь видно, зачем нужно forward. Помимо выхода, нужно понять, где считать производные. Поэтому мы храним все промежуточные значения. Получается, на выходе запоминаем все выходные значения слоев. Это нужно для обратного распространения ошибки. При обучении нейронок вы много раз делаете одно и то же: берете сигнал, распространяете слева направо, запоминаете промежуточные значения, считаете loss-функцию и начинаете считать производные в обратном порядке. Таким образом, считаете все градиенты, делаете градиентный спуск, снова переходите к forward propagation, backward propagation, и как только обновились веса, снова переходим к forward propagation.

Таким образом, вы итеративно работаете до тех пор, пока функция ошибки не примет удовлетворительное значение для всей нейронки. Понятно ли как нейронка обучается? Давайте вопросы, это довольно непросто. Если в чате вопросы, пишите. Вот, и сейчас пару моментов еще уточню. Давайте, вопросы еще. Возьмите, нарисуйте какой-нибудь простой нейрон, например, с 5 парными сигналами и промежуточным слоем не делайте слишком большим, просто несколько нейронов или один слой промежуточный и выходной слой. И попробуйте честно посчитать. производную. Если вы будете использовать механизм, который я объяснил, метод цепного правила обратного распространения ошибки, то есть цепочкой считать производную, вы увидите, что для их расчета необходимо сохранять промежуточные значения. Без них вы не сможете посчитать градиенты. Поэтому вам нужно использовать некий кэш, который вы будете повторно использовать при расчете градиентов. Так видно, что мы движемся справа налево, используя все эти веса и смещения, и выходные значения, а затем сохраняем все промежуточные значения, которые нам понадобятся для обратного вычисления градиентов. Здесь уже возникает dA, это и есть градиент. Вы считаете градиенты, и на основе этого получаете градиенты по параметрам. Как только вы получили градиенты по параметрам, выполняете обратное распространение ошибки. Этот процесс повторяется много раз, пока вы не достигнете удовлетворительного результата. 

Теперь возникает вопрос. Обратите внимание, что здесь также присутствует функция активации на весь слой, а сегмоида – это выходной слой. Если у вас бинарная классификация, использовав сегмоиду, вы получаете выходные значения от 0 до 1. После этого вам нужно рассчитывать лосс-функцию, а затем ошибку по этой функции. 

Теперь о том, как инициализировать веса. У нейросети должно быть начальное значение весов, и вы должны задать значение этих весов. Есть несколько эвристик о том, как это лучше сделать. Например, можно просто задать веса равными нулю, но это не рекомендуется, потому что в этом случае градиенты будут симметричными, что затруднит обучение. Если вы зададите веса, равные нулю, есть риск, что выходные значения будут слишком маленькими, что приведет к проблеме затухания градиента. Проблема затухания градиента возникает, когда каждый из градиентов оказывается малым, и произведение становится ещё меньше. 

Когда вы создаете много слоев, если градиенты близки к нулю, то обновления не происходят. Это проблема, поскольку чем глубже вы будете идти в нейронной сети, тем меньше обновления весов будут происходить. Для глубоких нейронных сетей это может затруднить обучение глубже расположенных слоев. Поэтому инициализация весов нулями не является хорошей практикой. Вместо этого можно использовать случайное распределение, чтобы задать значения, которые не слишком большие и не слишком маленькие, например, отразить их в пределах 0.1. 

Это важный момент, и есть различные подходы, о которых я расскажу позже. Даже в таких фреймворках, как PyTorch, уже существует функциональность для автоматической инициализации весов по указанным эвристикам. Начальные веса имеют огромное значение для процесса обучения нейросети. Кроме того, когда у вас много слоев, глубокая репрезентативность влияет на то, что в глубоких слоях у вас формируются более простые элементы, в то время как чем ближе к выходу, тем более сложные осмысленные фичи выделяются. 

Я рассказал, как устроены нейронные сети в целом. Если вы захотите реализовать это самостоятельно, имейте в виду, что фреймворки автоматически строят вычислительные графы и вычисляют производные. Однако, если вы хотите сделать это самостоятельно, помимо основного метода, необходимо избегать использования циклов, так как это существенно замедляет выполнение. Например, в линейной регресии, где осуществляется просто умножение на число, можно воспользоваться автоматизацией NumPy, чтобы избежать явных циклов. 

В заключение, меня интересует, как взялась идея нейронных сетей. Базовой концепцией является идея о том, что нейрон, подобно человеческому, обрабатывает входящие сигналы и производит выходные значения. Это математическая абстракция, и хотя она не является аналогией нейрона в биологии, она основана на тех же принципах. Важно разобраться в схеме устройства нейронной сети, распространении сигнала слева направо, а также в механизме обратного распространения ошибки. Если вы хотите найти дополнительные ресурсы, я рекомендую лекции Андрю Нг, которые подробно объясняют логику работы нейронных сетей и переход от логистической регрессии к нейронным сетям. Векторизация на весь дата-сет. Я вам показал, по сути, только для одного элемента из дата-сета. То есть, я вам показал векторизацию для одного элемента. И, конечно, все эти процессы применяются ко всем элементам из дата-сета. Это сложно разъяснить, поэтому не стал углубляться, но это тоже можно сделать. Здесь подробно об этом говорится. Если вам это интересно, посмотрите, вы действительно разберетесь в механизме работы нейронных сетей, посмотрев эту лекцию. А Егор вам будет дальше рассказывать, как это программировать и обучать. Вроде всё объяснил. Если есть вопросы, задавайте. Если всё понятно, дайте знать. Если кто-то хотел бы со мной пообщаться, пожалуйста, приходите. На этом всё на сегодня. Спасибо. До свидания.