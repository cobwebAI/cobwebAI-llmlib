Все, запись начала, отлично, теперь точно можно начинать. Так вот, быстро повторюсь, значит, мы сегодня с вами говорим про нейронные сети, наконец-то переходим, да? Вот, начнем с самых простых объектов архитектуры нейронных сетей, то есть это модель перцептрона. Из перцептронов мы будем делать с вами многослойные нейронные сети. Вот, соответственно, мы с вами говорили про постановку задач машинного обучения с учителем, то есть я быстренько напомню, что вот у нас есть данные x и ответ к ним y, то есть, опять же, это пример с квартирами, что у нас каждый враг, это некий объект квартиры, у каждой квартиры есть некие признаки и есть ответы, это цена. И, допустим, нам нужно предсказать цену, то есть у нас есть x, у каждого x при этом есть признаки, x1, x2, x3 и так далее, и есть y. И, соответственно, задачи машинного обучения строятся вот таким образом, то есть нам нужно подобрать алгоритм A таким образом, чтобы получать отображение из x к y. При этом мы понимаем, что невозможно на всех данных сделать абсолютно точное отображение, поэтому мы вводим loss-функцию, которая нам показывает, насколько близко мы приближаемся к ответам, то есть это функция ошибки. И задача сводится к тому, что нам нужно минимизировать эту функцию ошибки, и делаем это мы, меняя вот эти параметры модели. Да, кстати, сейчас я посмотрю, видно, а то вдруг я перегораживаю чуть-чуть камеру. Вы же демонстрируете, Петров. Да, это я понимаю, но мало же, чуть-чуть подумаем. Вот, окей, соответственно, мы с вами успели поговорить про линейные модели. Опять же, кратенько повторю, что формула для линейной модели выглядит таким образом, то есть это матричная запись. Я напоминаю, что мы пользуемся матричными операциями, и вы сегодня увидите, почему именно ими. Получается, что у вас функции для задачи регрессии это MSE и Maya. Мы с вами говорили, как они выглядят, что они делают, и, собственно, как это делается. То есть мы делаем градиентный спуск. И чтобы посчитать градиентный спуск, нам нужно посчитать, собственно говоря, градиент. И мы обсуждали, что линейная регрессия выглядит вот таким образом. Правда, транспонирование у нас было вот здесь, но это зависит от того, как вы задаете матрицы X, Y и так далее. То есть в этом плане это неважно, просто зависит от того, как вы задаете матрицы. Но в целом формула выглядит вот таким образом. И говорили с вами про задачу классификации, в частности, бинарной классификации. И говорили, что в классификации немножко по-другому выглядит задача. Нам нужно вот эту прямую выделить, которая разделяет объекты на два класса. И чтобы это сделать, мы вводим такую функцию сигнольда, на вход этой функции подаем линейную комбинацию. И предсказаниями тогда Y будет вот такая функция. То есть на вход этой функции подается линейная комбинация X на Y. То есть у нас появляется промежуточная переменная Z, которая является этой линейной комбинацией. И класс функции для логистической регрессии выглядит вот таким образом. Здесь у нас по глаголифуме вот эти самые предсказания. При этом кто-то мне напомнит, какие значения эти предсказания принимают в таком виде, которые после сигнольда. Это единички. Да, правильно. То есть сигнольда выглядит таким образом. Она стремится к нулю, стремится к единичке. И получается, что от нуля до единицы. И поэтому вот здесь будут значения от нуля до единицы. Но здесь один минус. А вот здесь стоят либо 0, либо 1. Соответственно, если 0, то вот это обнуляется. И остается вот это. Во всех класс функциях я напомню, что мы усредняем по всем объектам из датасета. То есть везде стоит сумма по всем объектам из датасета. Это то, что было в прошлый раз. И мы отталкивались от этого. Теперь будем строить с вами нейронные сети. Давайте сначала я вам расскажу, откуда вообще растут ноги. Почему нейронные сети стали вот так популярны. На самом деле, вы увидите, что у нас есть нейронные сети. На самом деле, вы увидите, что первые модели нейронных сетей были еще в 20 веке. Но они были в основном теоретические. То есть не было достаточно железа, вычислителей. Чтобы нейронные сети обучать, нужны данные и вычислители, чтобы их обучать. То есть нужно где-то хранить эти данные и их обучать. Поэтому даже в 90-х, когда компьютеры уже развивались и стали напоминать то, что мы сейчас видим, все равно была проблема именно с хранением данных. То есть вы помните эти дискеты, которые несколько мегабайт можно было хранить. Это еще в 90-х было. Я застал в это время. А вот уже начиная с нулевых, это стало развиваться, и появились видеокарточки. Вот тут как раз, там, где искусственный интеллект нашел хайп, это обучение нейронных сетей для распознавания образов на изображениях. Это сетка AlexNet. В общем, эта сетка, в чем прикол? Раньше применяли классические алгоритмы компьютерного зрения, чтобы решать эти задачи. А тут взяли просто нейронку, обучили, и она кратно превосходила по метрикам классические подходы. И вот тут люди поняли, что вот эту картинку, по сути. То, когда у вас есть данные, много данных, чем больше вы подаете данных, тем у вас качество нейронных сетей все больше и больше растет. А у классических алгоритмов машинного обучения, которые вы будете проходить в следующем семестре, они выходят, их качество выходит на некое плато. И, соответственно, получается, мы даже сейчас это видим. То есть какой-нибудь OpenAI берет еще жирнее модели, еще больше данных, и у них качество все растет и растет. Так, они уже весь интернет продаются. Ну, короче, они продолжают этот подход. Он заморгал. А что с ним? Он перегревается просто? Понятно. Но пока вас не было, только видели. Ничего. Блин, ну что делать? Я могу, в принципе, просто развернуть монитор. Давайте я договорю мысль. В общем, суть в том, что на нейронке они в этом плане, у них меньше ограничений по качеству, вы на них можете подавать больше данных, и их качество будет все лучше и лучше. И, собственно, когда в нулевые годы появились видеокарточки и стало возможным хранить много данных, тут вот нейронки хайпанули, и весь этот хайп пошел, по сути, начиная с нулевых 2010-го. По-моему, в прошлом году было 25 лет, когда он появился. Ну вот, это сейчас скажу. А получается, какой год-то? 1998. Да. Вот. Знаете что, я вам даже покажу видос. Сейчас подойдите. То есть нейронки хайпанули теперь, но какие-то сейчас фунтов. Еще раз вопрос. То есть сами нейронки, это именно зеберлинг или еще какие-то? Ну, в основном, да, я имею в виду, да, это как зеберлинг. То есть, скажите, а что это по сравнению с этими машинами, которые нейронки? Ну, потому что, давайте так, в принципе, алгоритмы линейной регрессии, они известны очень давно и давно использовались. На самом деле, весь этот хайп про data science и так далее, я как бы приводил даже личный пример. Я, по-моему, рассказывал, что я когда учился в университете, у меня магистрская диссертация была посвящена садачке, которая связана была с обработкой данных на большом адронном коллайдере. И там повсеместно применяются вот эти статистические подходы для обработки данных. И оказывается, это data science и machine learning, но вот эти подходы, мне кажется, были, грубо говоря, известны давно, и их применяли гораздо раньше, чем нейронки. Нейронки стало возможным применять именно из-за того, что возник вот эта возможность их обучать и хранить много данных. Ну, данные стало возможным, в принципе, тоже хранить чуть раньше, а именно применять видеокарты, чтобы их обучать, стало возможным относительно недавно. Поэтому, собственно, они вот так стрельнули в последнее время, и это все только набирает обороты. Собственно, да, ну да, тут, короче, я сразу скажу, у меня как бы слайды, они немножко недоделаны, потому что мы в процессе еще как бы, в процессе того, что делаем курс, но я буду иногда переключаться сюда. Кстати говоря, вот эти материалы, это вот курс на Курсере, но можно на ютубе найти видеозаписи выложенного. Там прям, я очень много подчеркнул отсюда. Короче, имею в виду, да. Ну, так вот, в чем проблема линейных моделей? Кто мне скажет? Можно предсказание линейной зависимости. Не все адаптируется. Ну, собственно, когда у вас возникает нелинейная зависимость, у вас линейная модель не очень хорошо работает. Да, вот тут пример, например, вот нелинейность, да, то есть, например, тут вот цены, там, сейчас, что тут? А, ну тут зависимость цены от размера, да, и видно, что здесь ноль-ноль-ноль-ноль, а потом с какого-то момента начинает расти, и тут возникает нелинейность, и получается, что ваша линейная модель здесь, ну, ее там, наверное, можно как-то вот так построить, да, но вот здесь возникает нелинейность, да. Вот, и здесь как бы приводится пример, да, что у вас вот есть разные фичи, да, и вы их можете подавать, независимо друг от друга на входы, и они дальше идут, могут идти в такие штуки, но это мы сейчас отдельно с вами поговорим, короче говоря, поэтому сейчас не буду на этом останавливаться. Про обучение с учителем я говорил, то есть, какие данные, с какими данными можно применять нейронные сети, то есть, это вот табличные данные, аудио, картинки, текст, это вы как бы и так знаете, вот, поэтому это мы быстро пропустим. Вот та самая картинка, которую я показывал, да, то есть, здесь вот, кто не видит, здесь традиционного алгоритма, да, традиционного, здесь там какие-то нейронные сети, а, и тут размеры нейронных сетей, то есть, это маленькие, средние, большие архитектуры, и видно, как у них меняется качество в зависимости от количества данных, которые вы туда подаете. Вот, собственно говоря, здесь показано, ну, как выглядит работа в deep learning, то есть, у вас появляется идея, вы ее забиваете в код, проводите эксперимент, получается обратную связь, и у вас возникает на основе этого новая идея, то есть, это такой очень довольно практичная область, ну, во многом экспериментальная. Вот, и давайте мы с вами к чему перейдем, сейчас я посмотрю. Да, собственно, давайте от логистической регрессии с вами будем переходить к нейронкам. Значит, проблема, собственно, да, линейных моделей в том, что как только у вас возникает нелинейность, здесь писать нельзя, да, получается? Ладно. Вы можете поднять проектор. Кнопка «поднять» у вас левого плеча, считайте. Лево-лево-лево-лево-лево. На стене лево так. Стена. А, все-все. Вы можете отпустить. А, так. Ага, все работает. Ну вот, грубо говоря, представьте, что у вас задача классификации. Сейчас выстраиваю. Продемонстрирую, да? Задача классификации выглядит вот таким образом. Вот у вас христики. Где-нибудь сейчас придумать бы еще как-нибудь, нолики. Но это я в признаковом пространстве, да? И как-нибудь... А, я придумал как. Смотрите, сейчас. Вот так вот нолики, то есть как бы вокруг этой штуки, да? А тут внутри христики. То есть получается, что вот эта поверхность, которая бы хорошо разделяла, выглядит таким образом. И тут бы никак как бы линейно это не сделалось, да? Поэтому линейная модель тут как бы... Вот это плохое качество, вот. Поэтому, собственно говоря, нужно придумать новые инструменты. Значит, в следующем семестре вы пройдете методы ближайших соседей, градиентный бустинг, случайный лест, о котором я говорил. Но они там тоже довольно специфичные. То есть они, вы увидите, что довольно специфичным образом линейные зависимости приближают. В этом плане нейронки, опять же, если их хорошо обучить и так далее, они более точно могут это сделать. Какая тут есть штука с этим связанная? Вот есть такая теорема, она чисто математическая. И суть ее заключается в том, что если у нас есть какая-то функция, и с какой точностью ее нужно приблизить, мы всегда с этим справимся, даже на слоне нейронной сети. То есть мы сможем подобрать такую нейронку веса, что она любую нейронную зависимость аппроксимирует. То есть вы уже здесь можете видеть, что такое нейронная сеть. То есть у нас есть входной слой, тут промежуточный слой и выходной слой. И тут видно, что, например, вот этот сигнал, он идет в каждый нейрон. Значит, вот этот сигнал тоже идет в каждый нейрон, и тут вот так много связи получается. Короче говоря, чисто математически было доказано, что если у нас есть какая-то функция абстрактная, мы можем ее аппроксимировать на слоне нейронной сети. Теперь давайте посмотрим, что такое нейронная сеть. То есть я вам показал, как выглядит именно сетка из нейронов, а вот что зашито в этот фиолетовый кружочек. Фиолетовый кружочек саши – это такая штука. Что здесь происходит? То есть у нас на вход идут какие-то сигналы, сигналы – это как раз наши данные, то есть это признаки. В случае с квартирой – это размер, что там было, район, вот это все. Цена метра? Нет, цена – это был таргет. Это то, что мы представили. То есть это то, что здесь такой идея как раз была. А здесь именно признаки. И это входные сигналы. Они на вход идут с какими-то весами, там V1, V2 и так далее. И еще есть у нас по-прежнему сдвиг, V0 некий. И это все суммируется. То есть модель перцептрона состоит из двух частей. Первая часть – это мы все сигналы суммируем и делаем это линейным образом. Что значит вес – это приоритет? Вес – это как линейная модель, мы взвешиваем сигналы. В этом плане это совпадает с линейной моделью. А вот дальше ключевой момент – это то, что мы применяем нелинейность. То есть это называется функция активации. Функция активации – это какая-то нелинейная функция. Мы сейчас с вами посмотрим, какие бывают. Но суть в том, что именно эта нелинейность позволяет нам аппроксимировать нелинейные зависимости. Давайте теперь посмотрим, какие функции активации бывают. То есть мы с вами уже видели, что логистическая регрессия применяется с игноида, но на самом деле есть разные функции активации. Есть гиперболический тангенс, который от минус одного к одному стремится. Есть вот такая функция, которая называется… Он, мне кажется, перегревается. Ладно, пока он думает, давайте уж как-то… Я могу просто разворачивать вот это. Ну, давайте я быстро тогда… Пусть так будет. Вам видно, нет? Ну, короче… Если что, поближе подходите пока. В общем, у нас функция активации, которая называется relu. Ее суть в том, что при отрицательных значениях она ровно 0, а при положительных, собственно, равна просто x. То есть это прямая под 45 градусов. Мы с вами обсуждали, что тут есть две проблемы. Во-первых, в нуле вот такой излом. И теоретически там может быть проблема со взятием производных. Но мы с вами обсудили, что на практике обычно этой проблемы не бывает. Тут проблема еще в том, что у вас при отрицательных значениях как бы нулевые значения. И получается, что вы, по сути, много сигналов просто обрубаете, потому что если они на вход нейрона идут отрицательные, то вы их просто обнуляете. И иногда, если вам хочется, чтобы их не обнулять, то можно применить лики РЕЛУ, так называемые. То есть это, когда у вас не 0, а другая прямая под другим углом. То есть у вас, получается, меньше 0 – это какой-то один угол, а больше 0 – другой угол. Ну и есть всякие разные. Вот есть ЕЛУ. Короче, их довольно много придумали. Но самые основные, наверное, которые нейрон как применяют – это РЕЛУ. Сигмойда. Я вам уже рассказывал, какие там могут быть проблемы. Я сегодня еще повторю. Гиперболический тангенс бывает. В принципе, любой из них можно применять и смотреть, что у вас получается. Сейчас я попробую пересопустить. Пока она думает. Собственно говоря, мы с вами сейчас структуру нейронок посмотрим. Но я давайте все-таки выведем сейчас. Мы с вами обсудим, собственно, как сигнал идет у нас. Как у нас сигнал распространяется в нейронных сетях. Давайте пока он думает. Такой вопрос на засыпку. Что будет, если у нас не будет функции активации? То есть если мы просто суммируем все сигналы... Давайте вот такой вопрос на засыпку. Что будет, если мы, соответственно, просто уберем из перцептрона функцию активации? Вот отсюда. Вот этого вообще уберем. Оставим только вот это. Линейная просто. Будет просто линейная функция. Даже если у вас будет много каких-то нейронок, но вы всех уберете функцию активации, у вас просто все линейные комбинации друг к другу будут складываться и останутся линейные комбинации. Это к тому, что функция активация – это ключевая вещь, которая нам позволяет делать аппроксимацию нелинейных зависимостей. Вот. Окей, собственно, обучение. Значит, давайте сейчас я вот тут буду щелкать иногда другим материалом. В общем, давайте посмотрим. Сейчас, секундочку. Значит, это мы с вами уже проходили. Тут рассказывается, что такое градиент. Сейчас это мы... Все. Соответственно, логистическая регрессия, как она выглядела еще раз, что у нас есть тоже линейная комбинация, но мы берем сигнойду и дальше применяем такую функцию. В случае нейронной сети у нас получается, что мы можем взять много нейронов. То есть, если в логистической регрессии у нас было только одно место, куда стекались все... Я хотел сравнение с логистической регрессией, как это выглядит. Представьте, что в логистической регрессии у нас получается, что по-прежнему красный входной сигнал стекается в одно место, и у вас output layer. Получается, что в логистической регрессии у вас не будет вот этого, и в фиолетовых будет только один кружочек. То есть, вот в этом разница получается. А в нейронных сетях, многослойных нейронных сетях у вас может быть несколько слоев и много нейронов в каждом слое. То есть, еще раз, давайте, знаете, как сделаем? Сейчас. Вот так вот сделаю. И получается, да, вот картинка внизу. Сейчас. Вот, видите, получается, что здесь все стекается в одно место, и там применяется сегмой. А здесь, видите, у нас получается много связей, много нейронов, много слоев. Ну, в данном случае два слоя. Вот в этом отличие, значит, отличие. Так. Сейчас. Так, продолжаем здесь. Да, может быть, на самом деле много выходов. Вот придумайте задачу, где может быть много выходов. Давайте, кто может проголосовать. Есть решение? Ну, несколько выходов, да, то есть у нас output layer, но... Ну вот, классификация. Да. Может быть, например, самый простой, наверное, как я вижу, который предъявляет кошку, собачку там. Ну, да, да, да. То есть вот есть dataset, есть такой dataset, который называется ImageNet, там тысяча классов и, соответственно, тысяча вот таких выходных нейронов. Ну, не нейронов, а выходов, да. Вот. Теперь давайте с вами рассмотрим прямое распространение. Вот сейчас нужно будет немножко напрячься, понимая, что конец дня и сложно, но давайте вот верхний уровень, давайте посмотрим, как это выглядит. То есть у нас, получается, есть... ну, будем на таком участке нейронной сети смотреть, то есть мы сейчас не будем прям всю нейронку смотреть, а просто участок, да. То есть вот у нас есть, как бы, грубо говоря, некий слой, мы его назвали ht-1, и ht — это выходной слой. И вот нам нужно посчитать, какие же будут выходы на основе значений, которые находятся здесь. И если абстрактно, да, то получается, что вот у нас есть вот эта самая функция активации, есть какие-то веса в большое. Мы, значит, эти веса домножаем на значения из вот этого нейрона, из этого слоя точнее, да, и прибавляем некий... еще некий вид. Вот давайте теперь подробнее рассмотрим, а что там лежит, потому что обратите внимание, что у нас здесь V, то есть это некая матрица с весами получается. И, собственно говоря, да, вот на всякие эти подписи не обращайте внимания, а сравнение, да, что было и что стало. То есть вот было вот так вот, то есть это просто линейная модель. Линейная модель — это мы наши веса домножаем на признаки, да, то есть это получается матричное произведение в строке на столбец. А теперь обратите внимание, что у нас здесь происходит. Здесь у нас появляется матрица V. Откуда она появляется? Она как раз появляется оттуда, что у нас теперь тут много нейронов, да, и у каждого нейрона будут как бы свои связи вот с этим слоем. То есть, грубо говоря, вот здесь вот 1, 2, 3, 4, 5, 6. Вот, например, вот у этого нейрона будет V1, V2, V3, V4. Вот у этого нейрона будет V1, V2, V3, V4. И так вот 6 раз. И получается, вот если вы сюда это посмотрите, то здесь как раз оно и есть, что у вас как бы, ну вот тут зависимость от того, как вы для себя решите. Но давайте так вот, количество строк пусть будет количество нейронов, а количество столбцов — это пусть будет количество связей со следующим слоем, да. То есть вот представьте, что V11, V12, V13, V14 — это будут веса вот эти вот. То есть V11, V12, V13, V14, да. И то же самое будет для этого нейрона, только у него будет V22, V23, V24 и так далее. Вот. То есть вот здесь уже видна разница между нейронкой и просто линейной моделью. Но как бы следует обратить внимание, что если вы каждую строку по отдельности будете умножать на эту штуку, у вас по отдельности будет вот это. Просто много раз вы это делаете. То есть получается, что… Поэтому я и начинал с линейных моделей, потому что на основе линейных моделей базируется, собственно, построение нейронных суцеидов. И, собственно говоря, здесь это и показано. Чтобы получить вот этот синий квадратик, вам нужно строчку перемножить на столбец. А зеленая, да, это будет вот в эту строчку умножать на этот же столбец. Ну, на вектор, вот, с вечами. То есть через каждую строку мы умножаем по отрицатели? Да, то есть получается, что у вас вот здесь на самом деле над каждой этой линией есть какой-то вес, по сути. И вы видите, что вес получается много. Поэтому и получается, что вам это удобнее в виде матриц выписывать. Вот почему я делал акцент на том, что в нейронках очень нужна матричная операция. Потому что вы… Вот такие операции сейчас… То есть в нейронках получается, что вот такие операции, они много-много раз выполняются для разных связей. И вы их можете сгруппировать с помощью матричных операций. Нейрон может передавать дальше… Ну, всегда один и тот же вес передает, или он разный может передавать? Если один… Там ставят симпатику. Наверное, верхний нейрон слева. Он правые нейроны разные веса передает? Да, да. Ну, получается, на выходном слой у вас было четыре красных кружочка, но на каждый кружочек будут другие веса разные. И эти веса будут подбираться в процессе обучения. Я сейчас вам покажу немножко другую иллюстрацию того, что я сейчас рассказал. Немножко более сложная, но как бы там прям подробно. Вот я поэтому призываю… Да, да, я знаю. Сейчас пока он будет думать, я вам сейчас открою прямо… Так, сейчас. Пока, кстати, открываю, расскажите, вот как семинар прошел. Клево было? Я так посмотрел, вроде прикольно там все. Егор сделал хорошее задание. Вот, так, сейчас. Я сейчас приду в следующий раз. Давайте пока запускайте, может, у вас… Все вам понятно, в чем фишка? Он… Это просто число. То есть каждый нейрон, к нему на вход приходит много чисел, они как-то агрегируются. И через функцию активации уже выходит одно число. Я когда-то задавался, почему… Точнее, нужны эти слои, почему нельзя, типа, создать обходной нейронный эффект? Ну, мы понимаем теперь, понятно, что функция активации. Ну да, функция активация. То есть согласно той теореме, с которой я начинал, вам нужен хотя бы один слой, чтобы нейронную зависимость аппроксимировать. А если бы вот то, что вы сейчас сказали, это, короче, вот это убрать и сразу сюда пустить сигнал. Это получается линейный… Много выходов. Ну… А, это, кстати, уже другой материал немножко, да. Ну, короче, я к чему. Вот здесь тоже показано, что вот у нас есть некий входной слой, скрытый выходной. И здесь показано, что вот здесь вот v1, v1. То есть получается v1 – это матрица 4 на 3. То есть вот в квадратных стопках один это означает, что… Сейчас включу. Да, то есть это означает на весь слой. На весь слой у вас веса будет матрица 4 на 3. Почему 4 на 3? Потому что 4 нейрона и 3 входных сигнала. То есть у каждого нейрона получается по 3 веса, да, получается. И таких нейронов 4, поэтому 4 на 3. И вот здесь даже прямо подробно расписывается. Я просто быстро вам покажу, чтобы вы видели. То есть вот для каждого нейрона получается вот такая вот запись. То есть опять два этапа, да. То есть линейная комбинация и нелинейная, да, и то же самое. И в итоге, короче, вот эта матрица, она как-то выглядит вот таким образом, да. То есть у нас получается… Ну, тут он просто не стал прямо расписывать, что 3 значения, да. Но суть в том, что каждая строка, это, короче, для каждого нейрона включается 3 веса, да. То есть здесь, получается, 3 столбца и 4 строки. И, получается, каждая строка — это веса соответствующего нейрона. 1, 2, 3, 4. То есть у вас получается матрица весов в итоге V1. И обратите внимание, что на выходе из каждого нейрона свой сдвиг. Потому что, если вы помните линейную модель, там один сдвиг на всю модель. А так как у нас здесь много нейронов и каждая нейрона — это модель сама по себе простая, да, то у каждого выхода еще свой сдвиг. Вот, такие дела. То есть это вот как бы… Это я вам рассказал, как у нас сигнал слева направо распространяется, да. Значит, итого получается что? Итого, получается, возвращаемся к нашим слайдам. То есть вот эта матричная запись. Итого у нас, на самом деле, вот то, что здесь изображено — это вот это. Давайте, вот кто мне сможет сейчас указкой расшифровать, что здесь происходит? Вот кто-то может подойти прямо и с указкой мне рассказать, что… Ну, угадать, расшифровать эту запись. Ну, или можете говорить, я буду… А это тип информации. Ну да, а это, соответственно, да. Это вот то, что здесь. Четыре числа будет. Ну, заточнее, стоп, не четыре числа. Сейчас скажу стоп. Получается… Давайте я попробую. Да, давай. А сейчас, видите, да, давай. Ну, здесь вот, наверное, 0, это место первого… Прикольненько. А f0 — это уже сам первый нейрон. Ну, вот, я поясню. А, да. То есть вот этот нейрон делает эту функцию. Да. Вот. Получается, v1 — это, скорее всего… Ну, v1, да. Почему v1? Ну, получается, на вход, наверное… А. v1 выглядит понятно. Наверное, вес, вот этот нейрон добавляет вес, но почему он v1? Понятно. Может быть, потому что он переходит в этот нейрон? Не, ну, в плане, почему v1, это… Ну, давайте сейчас, во-первых… Во-первых, x — это вот это желтое, да? Это все в целом… Да, x — это все желтые значения. x — это x. Значит, дальше, ну, этот x с какими-то весами b0, обратите внимание, b0 плюс означает, что b0 застыкает все веса, которые здесь на этими линиями, да? И плюс некий b0 тут тоже как бы застыкает все веги сразу. То есть это матричная запись, получается, и f0, да, это некая функция активации, применяется здесь, вот, и получается, что на выходе вот из этого, на выходе из этого мы получаем значение для этого слоя, для слоя 1. Дальше, соответственно, мы используем значение этого слоя, чтобы получить значение для этого слоя. И поэтому получается, что для того чтобы посчитать значение этого слоя, мы значение вот этого слоя теперь домножаем на матрицу b1, и получается, что b1 зашитрит все веса, которые здесь. Вот. И получается к этому применению f1 получаем значение здесь. Теперь дальше вот, чтобы получить значение для этого слоя, мы значения, которые получились здесь, мы домножаем на b2, то есть b2 зашитрит все, что здесь. И получаем, соответственно, значение здесь. То есть это получается здесь. В итоге мы получаем вот то, что здесь. Ну и, наконец, мы домножаем на b3 выхода из этого слоя, и получаем конечное значение. То есть получается, что b3 зашитрит все вот эти нейроны, которые здесь. И получается в итоге, что если вот это все сделать, мы получаем выходные значения. Теперь обратите внимание, что это математическая запись. Как бы я почему вот хотел подробно вам это рассказать, потому что получается, что, например, чтобы получить 2,2, вам нужны значения, когда... Ну, то есть, точнее, чтобы получить значение, например, скрытого слоя 2, вам нужны значения скрытого слоя 1, которые, в свою очередь, получаются из значений вторных. То есть это как такой матрешка, то есть как будто чем дальше идем, тем более получается такая запись возрастает. Но в корне этой записи лежит простая вещь. Вы просто используете значение предыдущего слоя, а, в свою очередь, посчитайте этот слой, вы используете значение еще более предыдущего слоя. В итоге получается, что, чтобы получить значение на выходе, у вас используются все вот эти связи, все слои и так далее. То есть как бы вот эта запись, это вот это. Просто F это получается уже функция активации? Ну, да, везде это функция активации. Здесь это может быть на выходе. Я вам расскажу, что здесь может быть на выходе. То есть, на самом деле, если F0, F1 и F2 это может быть ReLU, то для F3 там можно применить Softmax. Но вот такой Softmax мы дальше используем. Почему мы пользуем матрицу? Ну, на выходе получается... Вот это хороший вопрос, потому что... Четыре выхода? Да, четыре выхода. Можно конкретно, допустим, смотрите сколько можно сделать. Сейчас. Я просто сразу пытаюсь вспомнить, как это реализовано в соответствующих библиотеках. И, по-моему, там... Да, там, по-моему, там зеленые выходы. Да, то есть четыре значения, они дальше используются в любой расчетной функции. Но вы можете просто взять какое-то конкретное значение и соответственно... То есть, например, на выходе, что можно взять? Смотреть самый большой вес, и значит... Смотреть самый большой вес, значит... Ну, там, кошка. Ну, смотрите, да. То, о чем поговорили, это только вы смотрите значение, которое здесь, и наибольшее значение будет соответствовать классу, который предсказывает индексу класса, который предсказывает нейронку. Ну, это вы на семинаре увидите. Короче говоря... Да, это правильно то, что вы говорите. Поэтому... Ну, опять же, в плане, что на выходе получится, зависит от того, что у вас будет в качестве V3 и так далее. То есть, если на выходе... То есть, если у V3 размерность будет на выходе 4, то вы получите 4 значения. Правильно вообще? Ну, да, да, правильно. Окей. И таким образом, вот... Короче, давайте я опять разверну. Вот это... Будет своя матрица весов, своя... Ну, функция активации, это зависит от того, как вы зададите. Обычно в рамках одного слоя задают одну и ту же функцию активации, но для разных слоев можно разные принципы. Не, ну можно, но обычно так не делают. Почему так не делают? Потому что вам нужно будет делать обратное распространение ошибки, и чем сложнее вы это будете задавать, тем сложнее будет считать эти градиенты. То есть, обычно все, кто пытается в этом плане не слишком переусердствовать. То есть, по-хорошему, на картинке между слоями надо нарисовать еще полуксоциал. Ну, по-хорошему... Ну да, тут везде зашита функция активации. На выходе из каждого слоя, вот здесь, грубо говоря, есть нелинейность этого слоя. То есть, это матричная запись так называемого inference. Что такое inference? У вас есть на входе иксы, и вы их распространяете, чтобы получить выходные значения. То есть, это, получается, распространение сигнала слева направо. То есть, представьте, что вы уже нейронку обучили. Если на вход приходит икс, чтобы получить выходные значения, вам нужно совершить, по сути, вот такие операции математические. Поэтому, по сути, работа нейронок – это просто перемножение матриц между собой, с математической точки зрения. А теперь давайте, собственно, посмотрим, как их теперь обучать. Только вот мне, чтобы вам это рассказать... Да, вот сейчас получилось. Сейчас оно вернется. Если вопросы есть в чате, тоже задавайте. Сейчас я проверю, у нас все идет. Напишите там плюс всего нормального в чате. Да, все плюс. Хорошо, спасибо. Вот, сейчас проект отключится, и я продолжу. Так, а теперь, собственно, мы с вами будем говорить про обучение. Вот, напомните, как мы уже умеем обучать модели машинного обучения. Какой мы метод с вами рассмотрели. То есть, что нужно сделать, чтобы обучать модель машинного обучения. Камон, я в начале лекции шла. Ну, если вы подавали часа... Ну, веса, да. Вот как веса пропустить? Ну, нужны данные и результаты ответов. Так, и дальше, что мы делаем? Вот у нас есть ответы, да, и есть выходы модели. Что с этим можно сказать? Считать ошибки. Дальше считаем ошибки и минимизируем. Вот, а как минимизируем? Я это все почему? Потому что для нейронов остается все то же самое абсолютно. Уже знакомая вам формула. Мы для каждого веса... То есть, представьте, у вас получается здесь куча-куча... Вот над каждой линией у вас есть свой какой-то вес. И вот для каждого веса вам нужно совершить такую операцию. И как вы видите, чтобы ее совершить, вам нужно посчитать производную. Причем много производной. И как вы можете понять, чем дальше у вас идет вглубь нейронки, тем больше надо сделать вычислений. Это логично. Потому что, как я вам говорил, смотрите, можно вернуться вот в эту запись. Чтобы посчитать производную по V0, вам нужно... Видите, сколько здесь внешних оболочек? То есть, получается 1, 2, 3. То есть, вам нужно как минимум начать снаружи и внутрь вот так вот считать. И получается, что аналитически это делается не очень здорово. Особенно когда у вас глубокая нейронная сеть. Вот просто в лоб считать производную не очень здорово. Поэтому придумали такой лайфхак математический. Я про него говорил прямо на первой лекции. Он лежит в основе нейронных сетей. И в частности, вот Джеффри Хинтон, который получил Нобелевскую в этом году за физику, он этот метод разработал. Собственно, в чем заключается суть? Суть заключается в том, что мы сначала строим граф вычислений. Значит, это просто некая иллюстрация абстрактная. То есть, это не связано с этой картинкой. Это просто некая математическая абстракция, чтобы вам объяснить, в чем заключается метод. Представьте, что вы хотите обновить эти веса. При этом вычислительный граф, представьте, что у вас какая-то абстрактная математическая функция. То есть, чтобы получить выход, у вас есть две... Короче говоря... Да, ну, соответственно, то есть, что здесь нарисовать? Представьте, что получается у равно x1v1, и на это навешивается сигнал 1. В свою очередь сюда еще прикол будет сигновать сюда. А сюда приходит сигнал и от x1, и от x2. И они все, короче, агрегируются здесь. И дальше мы получаем некий высот, да? Так вот, чтобы посчитать производные, можно воспользоваться лайфхаком. Значит, мы вводим такие... Можно ввести такие промежуточные перемены. Здесь, допустим, у1, у2, да? Вот. И чтобы посчитать производные по у1, вам нужно отследить от выхода. Теперь мы двигаемся справа налево. Нам нужно отследить, каким путем нам нужно пройти, чтобы добраться сюда. Мы видим, что мы идем справа налево, идем-идем-идем, и вот по этому пути мы сюда набираемся. Теперь мы смотрим, какие у нас функции стоят у нас на пути. Мы видим, что у нас возникла сигмойда, значит, у нас будет производная dl по d сигмойда. Дальше мы берем производную, теперь сигмойда по у, потому что мы уже здесь, и нам сюда нужно. Теперь отсюда сюда, это просто получается dy по d сигмойд, и, наконец, последняя производная получается d сигмойд по dy у1. И получается, чтобы посчитать вот эту производную, которая... Обратите внимание, нашу задачу считать производную вот этой тугой функции, вот, у1. И получается, что она, согласно методу взятия производных сложных функций, она равна произведению всех этих производных. Получается, чтобы нам посчитать производную отсюда, выходной функции по d переменной, нам нужно построить вычислительный граф, посмотреть путь распространения сигнала назад и взять все частные производные, которые у нас окажутся на пути, и перемножить их. На самом деле можно было бы просто напрямую считать вот эту штуку. Но я потом приведу пример, можно взять какую-то функцию, например, ту же сигмойду, и брать напрямую производную. Но эта практика показывает, что когда у вас сложные функции, это делать гораздо сложнее, чем если вы разбиваете на вот такие функции. Потому что, как правило, вот такие производные по отдельности, они гораздо проще. Получается, что метод заключается в том, что вы берете выходную функцию и считаете все эти производные, которые у вас окажутся на пути, и получается в итоге делать вот такие операции. Как вы можете понять, мы хотели по v1 считать, то есть по v1 у вас просто добавляется множитель du1 по dv1. Вот финальный пункт здесь, еще один множитель. И получается dn по dv1 будет все то же самое, только вы здесь добавляете еще один множитель. Вот такой метод называется chain rule, или метод обратного распространения ошибки. Получается, что, еще раз, как выглядит обучение нейронок. Получается, сначала вам нужно посчитать сложную функцию, а чтобы посчитать сложную функцию, вам нужно распространить сигнал слева направо. И получается, что вы сначала высчитываете выходной сигнал, для этого слева направо двигаетесь. Вот вы, как только получили выходной сигнал, можете посчитать сложную функцию. И как только вы посчитали сложную функцию, вы теперь обратно двигаетесь и берете все производные на пути и просто начинаете их перемножать. И как только у вас какой-то градиент появился, вы его применяете для метода градиентного спуска. То есть вы для каждого слоя можете делать свой градиентный спуск. Как только у вас появился градиент, вы сразу можете применить градиентный спуск. Получается, вот в этом и заключается метод. Он называется backpropagation. Почему backpropagation? Это буквально обратное распространение ошибки называется метод. Потому что вы считаете ошибку, и вы буквально справа налево занимаетесь вычислениями. Сигнал как будто справа налево обратно идет. Но не идет, а вы считаете все эти производные. Я теперь вам покажу, как это можно еще раз смотреть. Я еще раз повторяю, что в этой лекции супер подробно. Я многие вещи сейчас опустил, но тем не менее. Здесь как бы немножко сложно, поэтому я не буду. Да, вот смотрите, вот эта схемка. Давайте так. Зачем нам нужно слева направо распространять сигнал? Чтобы обучать нейронке, нам нужно сначала сделать forward, а потом backward. Вот здесь видно, зачем нам нужно делать forward. Дело в том, что помимо того, что нам нужно выходной сигнал считать, нам нужно еще в процессе понять, а в каких местах нам считать производные. То есть нам нужны все промежуточные значения, нам тоже нужны. Давайте я попробую на примере экрана. То есть, грубо говоря, получается вот здесь выходной сигнал, вы можете здесь увидеть, здесь написано cache и все промежуточные значения. То есть мы на самом деле, грубо говоря, мы еще параллельно храним все выходные значения слоев и так далее. Почему мы это делаем? Потому что они используются, когда мы будем делать обратное распространение ошибки. То есть получается, что в любом случае при обучении нейронок вы что делаете? Вы много раз делаете одно и то же. Берете сигнал, распространяете слева направо, запомнили все промежуточные значения, посчитали loss-функцию и дальше начинаете считать производные в обратном порядке справа налево. И вот таким образом вы посчитали все градиенты, сделали градиентный спуск, теперь снова вы слева направо двигаетесь, считаете все значения. У вас нейронка же обновилась, когда вы веса поменяли. И вы с обновленными весами снова сделали forward propagation, backward propagation, снова у вас веса поменялись. И вот так вот итеративно вы делаете на тех пор, пока функция ошибки не примет удовлетворительное значение для всей нейронки. Понятно ли в целом механизм, как нейронка обучается? Давайте вопросы, потому что это довольно непросто. Какие у вас, может, вопросы? Пока включу проектор. Если в чате тоже есть вопросы, пишите. Вот, и сейчас я вам буквально пару моментов еще уточню. Давайте, вот вопросы еще. А вот вы просто, это, кстати, хорошее упражнение, возьмите, нарисуйте какой-нибудь устройственный нейрон, например, 5 парных сигналов, и промежуточный слой не делайте сильно большой, просто несколько нейронов, допустим, да даже можно один слой промежуточный сделать, и какой-то выходной слой. И попробуйте честно посчитать производную. Вот если вы будете делать по тому механизму, который я объяснил, по методу chain rule, то есть обратного распространения ошибки, и цепочкой считать производную, вы увидите, чтобы их считать, вам нужно было выводить отмечения. Просто без них вы не сможете считать градиенты. Поэтому вы, как бы, заслуживаете, грубо говоря, некий кэш, вы его переиспользуете, когда считаете градиенты. Вот. И это как раз вот здесь видно. То есть, грубо говоря, мы справа налево, когда идем вот эти все там веса, там какие-то сдвиги, и вот выходные значения, а дальше мы все вот эти промежуточные значения сохраняем, и дальше переиспользуем, когда считаем градиенты обратно. Вот здесь уже как бы возникает dA, это уже градиент, да? И вот. И считаете градиенты, и на основе всего этого получается градиенты по параметрам. И как только вы получили градиенты по параметрам, делаете обратное распространение ошибки. И так вот много-много раз вы делаете, пока вам этого не хватит. Вот. Теперь возникает вопрос. Вопрос следующий сейчас. Да, кстати, обратите внимание, что здесь еще вот функция активации на весь слой, а здесь сегмойда – это уже выходной слой. Там, допустим, если у вас бинарная классификация, делаете сегмойду и получаете выходные значения от 0 до 1. Вот. Дальше считаете лозунг функцию, дальше ошибка по лозунгу функции. Короче говоря, дальше то, что я рассказал. Вот. А теперь возникает вот вопрос. Сейчас я его… Да, вот здесь, кстати говоря, отвечаем на ваш вопрос, да? Обратите внимание. Вот чтобы посчитать, допустим, какой-то… То есть здесь приведена формула в целом для какой-то нейронной… Ну, для тех нейронных сетей, которые мы рассматривали. При этом функция активации здесь бинарная… Бинарный логлос. Ну, да, бинарный логлос. Вот. И, короче говоря, здесь вы видите, что, например, чтобы посчитать производную d, v, l, здесь используется значение a, l. И получается, мы получаем как раз, когда идем слева-направо. Поэтому… Ну, я просто не стал вводить эту формулу, потому что это… Ну, то есть их можно без проблем вывести. Я просто вам в целом механизм объяснил. Но проследить, как это происходит, полезно. То есть обратите внимание, что здесь везде матричная операция, да? Потому что у вас там много весов, много параметров. И для каждого нейрона это расписывать не имеет смысла. Вот. Поэтому матричная операция. То есть, еще раз, получается, слева – это forward, справа – это backward. Вот. Хорошо. Так. А теперь я вот что хотел вам еще рассказать. Сейчас. Сейчас. Надеюсь, это было… Пожалуйста. Сейчас, ребята, я найду это место. Где-то я вот его только что видел. Вот он. Теперь вопрос. Вот, собственно, вот с этим. Вопрос о том, как висать и инициализировать. Потому что у вас должно быть некое начальное значение весов. Оно же не просто… У вас какое-то определенное… То есть, как вообще, еще раз, да? Вот у вас есть нейронка. Изначально она не обучена. Это означает, что у нее есть какие-то веса. Но эти веса, вы их должны как-то задать, значение этих весов, да? И получается, что есть некие эвристики, как это лучше сделать. То есть, я вам сейчас расскажу, как лучше не делать. Вот. Можно просто взять и все задать нуля. Но вот здесь на примере совсем простейшей нейронки показывается, что так делать не очень хорошо, потому что у вас там на выходе получаются вот такие вот какие-то симметричные градиенты. И, короче говоря… Ну, тут просто берется напрямую, считается, дальше берутся градиенты, и покажется, что градиенты у вас будут вот такого вида. То есть такие симметричные градиенты. И это не очень хорошо с точки зрения обучения получается. Помимо этого, если вы зададите нулями, да, все, у вас может возникнуть риск того, что выходные значения будут принимать маленькие значения, и у вас может возникнуть вот эта проблема затухания градиента. Кстати, откуда возникает проблема затухания градиента? Вот это видно, кстати, вот здесь. Она как раз из-за этого и возникает. Что если каждый из этих градиентов маленький, то вот это произведение будет еще меньше, получается. А места между слоями не меняются? Не очень понял. Ну, когда нажимаешь несколько слоев… Или мы сразу задаем, вот там слои описали, и они такие остаются? Не, они меняются. В том-то и дело, что если у вас градиенты нулевые, ну, близки к нулю, то они не будут обновляться. И… А вот это проблема. Да, да. А если градиенты… Ну да, здесь все это градиенты. И если вот каждый градиент принимает небольшое значение, то все это произведение тем более будет маленькое. И получается, чем глубже вы будете идти внутрь нейронной сети, тем меньше у вас будет обновления весов. То есть поэтому для глубоких нейронных сетей есть риск вот этого вот того, что обучение для глубоких слоев будет проходить хуже, чем для выходных. И тут как раз поэтому нулями задавать не очень хорошо. То есть я вам дальше расскажу про эвристики, но можно, например, вот сделать таким образом, то есть, грубо говоря, задать значения не очень большими, не очень маленькими, а как бы что-то такое между, да, грубо говоря. То есть можно, допустим, взять какое-то равномерное распределение случайное, но обножить на 0,1, чтобы оно не было слишком большое. Ну, короче, это такой момент немного эвристический. То есть тут есть некие подходы, но я про них чуть дальше расскажу. Просто тут в целом я... А вы же связались с параномами, Славик? Да. С параномами, Славик. Ну, как бы здесь да, но вообще есть некие эвристики, как лучше это сделать, и я про это расскажу на следующем занятии, если не забуду. Там есть специальные методы, я вам потом ссылку пришлю, как они называются и как выглядят. Там немножко более сложная эвристика, но в целом есть подходы, как лучше сделать. То есть если взять тот же PyTorch, вы когда там программируете нейронную сеть, там обычно уже на автомате с какими-то весами задается, с теми самыми эвристиками, которые я сейчас говорю, не с этими, которые есть подходы, просто я про них чуть дальше расскажу. Это первый момент, что у вас, получается, результат будет сильно зависеть от того, с каким начальным приближением вы начнете обучать нейронку. И что еще? И тут про что рассказывают? Тут рассказывают про то, что у вас, когда много слоев, и, допустим, у вас задача какая-то на компьютер визент, то тут глубокая representation. То есть, грубо говоря, в глубоких слоях у вас будут более простые элементы, фичи. То есть на выходах из нейрона в более глубоких слоях у вас будут создаваться какие-то совсем простые фичи. И чем ближе к выходу, тем больше у вас в выходе будут напоминать уже что-то более осмысленное. Это возникает из-за того, что вы обучаете, и так получается, есть такая некая штука с нейронкой, что в глубоких слоях у вас более простые фичи задаются, и дальше, чем ближе к выходу, тем у вас более что-то осмысленное. Это если не интуитивным образом рассказывать. Есть целые работы, которые изучают, как слои нейронных сетей, есть ли в них какой-то смысл, пытаются изучать, как слои что-то физическое создают и так далее. Особенно я видел работы, связанные с LLM, но фишка в том, что чем больше у вас нейронка, тем сложнее уже анализировать, потому что у нее куча слоев, куча параметров. Но некая интуиция в этом заключается. Что еще вам рассказать? В принципе, я рассказал, как обличаются нейронки в целом. Получается, здание именно из-за этого архитектура? Ну, не прямо из-за этого архитектуры, а в целом. Из-за идеи линии? В целом, да. Смотрите, я чуть подробнее расскажу. То есть там оба этих человека, с которыми дали, там один Кинтон, а другой Хопкинс, по-моему. И оба они стояли у истоков. То есть один из них как раз предложил метод обратного распространения ошибки. Но обоим дали формально, грубо говоря, им дали за то, что они придумали всякие архитектурки, причем придумали их на основе неких физических инсайтов, то есть на основе физических, как это сказать. То есть у них в голове крутилась некая физическая модель, они ее переложили в виде математики и получили какие-то… Там модель Больцмана еще, вторая какая-то модель, а, ну и модель Хопкинса. То есть они ее получили на основе инсайтов из физики. В итоге это стало существенным вкладом в нейронки, то есть вот эти все вещи. И поэтому, ну, почему именно за физику дали, непонятно, но вот считается, что в формальном релизе написано, что они на основе физики вывели свои вот эти нейронки. Но сами нейронки стали активно применяться не только физике, а в разных областях. В общем, вот если вкратце, то получается такая история. Значит, сейчас. Что я хотел сказать? Давайте последний момент скажу. Если вы захотите запрограммировать это своими руками, то есть понятно, что сейчас есть фреймворки, которые это все делают. Тот же PyTorch, он автоматически умеет строить вот эти самые вычислительные графы и высчитывать производные. То есть как это делать дальше, вот Егор на семинарах расскажет. Но, допустим, вы хотите вот это упражнение сделать это сами, да? Вот чтобы сделать это сами, вам нужно будет применить один лайфхак, про который я сейчас расскажу через буквально одну секунду. Лайфхак вот в этом заключается. Сейчас. Запустилось, да? То есть лайфхак заключается в том, что как можно меньше использовать циклы всякие, потому что это сильно замедляет, во-первых, во-вторых, усложняет. То есть на примере вот таких простых вещей, что… Лямбда функции. Не, не лямбда функции, а просто вот простой пример. Простой пример, да? Там было, например, wx плюс b, и b – это столбик с числами. Но все числа одни и те же, например, для линейной регрессии, да? У вас получается, что вот если b – это 100, а вам нужно 4b, вы можете оставить это просто 100, он автоматически… Ну, в NumPy, например, он автоматически из этого сделан. Столбик отпиливаем, и тогда у вас операция как бы получится. Грубо говоря, поэтому получается и здесь дальше вот такая штука, что когда речь идет о всяких операциях сложения, учитания и так далее, или умножения на число какое-то, то не надо городить цикл. В том же NumPy это все делается, автоматически они это все делают. Или, например, в Sigmoid там экспоненты, да? Вы меняете экспоненты от минус x на y. То есть вы можете просто сделать np.x и дальше туда сразу матрицу задать. Он для каждого элемента матрицы применит экспоненты. То есть вам не нужно писать цикл for, и в этом цикле писать для каждого элемента экспоненты. Ну, короче, это просто некие такие лайфхаки. Растить себе жизнь, если вы захотите это делать. Мы как раз, кстати, к 9 подходим. В принципе, на самом деле у меня особо добавить в ходе ничего такого. То есть я призываю посмотреть материалы, посмотреть отдельно лекции. Но давайте закончим тем, что откуда вообще взялась вот эта тема, что нейронная цель. Типа вот человеческий нейрон, там тоже, как получается, есть некое ядро, в это ядро приходят сигналы. То есть каждый нейрон связан с другим нейроном. И они связаны вот через такие вот штуки. И приходят сигналы, они как-то там обрабатываются и уходят дальше. Но это просто какое-то выходное значение. Но суть как бы в том, что надо понимать, что вот это и вот это, это, конечно, не прямая аналогия, потому что, мне кажется, нейробиологи до сих пор может не очень понимать, что вот здесь происходит в ядре реального нейрона человеческого. Но это чисто вот такая математическая абстракция. И просто из-за того, как это похоже выглядит, вот эта картинка, да, она, опять же, не надо... Это прям реальная модель. Сейчас, давайте здесь... Вот эта модель, да. То есть это просто некая математическая абстракция, просто ее назвали нейронной сетью, потому что тут тоже, кажется, вот этот нейрон связан с предыдущим, тоже идут какие-то сигналы, какие-то нелинейности. Но надо понимать, что вот нелинейности, которые в этой модели, они, конечно, уже гораздо проще, чем то, что реально происходит. Но это просто некая математическая абстракция. Поэтому назвали нейронной сетью. Короче, из этой лекции, да, вам нужно вынести еще раз, по сути, вынести две вещи. То есть как происходит вот эта вещь, ну, точнее, три вещи. Во-первых, как выглядит устройство отдельно нейрона. То есть еще раз, да, вот выглядит это таким образом. Дальше вам нужно вынести, как вот выглядит распространение сигнала слева направо. И, наконец, вам нужно разобраться, как работает механизм обратного распространения ошибки или chain rule. Если вы захотите подробно это прям смотреть, те формулы, как это выглядит, то вот можете смотреть вот эту PDF, там немножко непонятно, но можно найти в YouTube видеозапись с этой лекцией, там, соответственно, это сопровождает. То есть можно проследить. Мне лично, для понимания, очень помогла эта лекция. Это вот из курса, из специализации Deep Learning. Это Deep Learning, можете прям загуглить в YouTube. Ну, короче, пока он немножко работает, можете в YouTube пить и прямо эти лекции найти. Там прям мужик, что мне лично очень понравилось, что он прямо суперподробно выводит вот эти вещи. Сейчас покажу, какие. То есть он начинает с логистической регрессии. Это Андрю Анджи. Да-да-да, это Андрю Анджи. Он начинает с логистической регрессии и показывает дальше переход к нейронке и показывает, особенно здесь, он прямо для каждого нейрона расписывает эти уравнения, дальше показывает, как это все векторизуется. Причем он это показывает в векторизации дальше идет. То есть он показывает векторизацию на весь дата-сет, а я вам показал по сути только для какого-то, грубо говоря, я вам показал для одной строчки из дата-сета. А не NG, а IN? Ну, IN, да. То есть, я вам, по сути, показал векторизацию для одного элемента из дата-сета. И, конечно, вот эти все вещи для всех элементов из дата-сета он ищет. Ну, это сложно здесь разобраться, поэтому не стал рассказывать, но это тоже можно сделать. И вот здесь он подробно про это говорит. Короче говоря, если вам это будет интересно, посмотрите, потому что вы прям реально разберетесь, как механизм работы нейронных сетей, посмотрев эту лекцию, разберетесь вы. Ну, а, соответственно, Егор вам будет дальше рассказывать, как это программировать, обучать, собственно. И вот так и так. Вроде я все разобрел. Если что. Так, а ну-ка, Teams, если есть вопросы, давайте. Потому что, в принципе, я рассказал то, что хотел с вами. Общайте плюсы, если все было понятно. Если кто хотел со мной пообщаться, то, пожалуйста, приходите. А так все на сегодня. Спасибо. До свидания. Редактор субтитров А.Синецкая Корректор А.Егорова