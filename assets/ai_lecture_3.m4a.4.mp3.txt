выходную функцию и считаете вот эти все производные, которые у вас окажутся на пути, и получается в итоге делать вот такие операции. То есть, как вы можете понять, мы хотели по v1 считать, то есть по v1 у вас просто добавляется множитель du1 по dv1. Вот, финальный пункт, вот здесь еще один множитель. И все, получается dn по dv1 будет все то же самое, только вы здесь добавляете еще один множитель. Вот такой метод называется chain rule или метод обратного распространения ошибки. Получается, что, еще раз, так выглядит обучение нейронов. Получается, сначала вам нужно посчитать слоз функции, а чтобы посчитать слоз функции, вам нужно распространить сигнал слева направо. И получается, что вы сначала высчитываете выходной сигнал, для этого слева направо двигаетесь. Вот вы, как только получили выходной сигнал, можете посчитать слоз функцию. И как только вы посчитали слоз функцию, вы теперь обратно двигаетесь и берете все производные на пути и просто начинаете их перемножать. И как только у вас какой-то градиент появился, вы его применяете для метода градиентного спуска. То есть вы для каждого слоя можете делать свой градиентный спуск. Как только у вас появился градиент, вы сразу можете применить градиентный спуск. Получается, в этом и заключается метод. Он называется backpropagation. Почему backpropagation? Это буквально обратное распространение ошибки называется метод. Потому что вы считаете ошибку, и вы буквально справа налево занимаетесь вычислениями. То есть сигнал как будто справа налево обратно идет. Но не идет, а вы считаете все эти производные. Я вам сейчас покажу, как это можно еще раз смотреть. Я еще раз повторяю, что в этой лекции супер подробно. Я многие вещи сейчас опустил. Но тем не менее. Здесь как бы немножко сложно, поэтому я не буду. Смотрите, вот эта схемка. Давайте так. Зачем нам нужно слева направо распространять сигнал? Чтобы обучать нейронке, нам нужно сначала сделать forward, а потом backward. Вот здесь видно, зачем нам нужно делать forward. Помимо того, что нам нужно выходной сигнал считать, нам нужно еще в процессе понять, а в каких местах нам считать производные. Нам нужны все промежуточные значения. Давайте я попробую примерить рано. Грубо говоря, получается вот здесь выходной сигнал. А вы можете здесь увидеть, здесь написано cache и все промежуточные значения. Мы, грубо говоря, еще параллельно храним все выходные значения слоев и так далее. Почему мы это делаем? Потому что они используются, когда мы будем делать обратное распространение ошибки. Получается, что в любом случае при обучении нейронок вы много раз делаете одно и то же. Берете сигнал, распространяете слева направо, запомнили все промежуточные значения, посчитали loss функцию и дальше начинаете считать производные в обратном порядке справа налево. Таким образом вы посчитали все градиенты, сделали градиентный спуск. Теперь снова вы слева направо двигаетесь, считаете все значения. У вас нейронка же обновилась, когда вы веса поменяли. И вы с обновленными весами снова сделали forward propagation, backward propagation. Снова у вас веса поменялись. И так итеративно вы делаете до тех пор, пока функция ошибки не примет удовлетворительное значение для всей нейронки. Понятно ли в целом механизм, как нейронка обучается? Давайте вопросы, потому что это довольно непросто. Какие у вас вопросы? Так, пока включу проектор. Если в чате тоже есть вопросы, пишите. И сейчас я вам буквально пару моментов еще уточню. Давайте вопросы еще. А вот вы просто, это, кстати, хорошее упражнение. Возьмите, нарисуйте какой-нибудь простенький нейрон, например, 5 парных сигналов. И промежуточный слой не делайте сильно большим, просто несколько нейронов. Допустим, даже можно один слой промежуточный сделать и какой-то выходной слой. И попробуйте честно посчитать производную. Если вы будете делать по тому механизму, который я объяснил, по методу chain rule, то есть обратного распространения ошибки, и цепочкой считать производную, вы увидите, чтобы их считать, вам нужно было выйти дальше. Просто без них вы не сможете считать предельно. Поэтому вы, как бы, заслабился, грубо говоря, на некий кэш и переиспользуете, когда считаются градиенты. И это как раз вот здесь видно. То есть, грубо говоря, мы справа налево, когда идем вот эти все там веса, какие-то сдвиги и выходные значения, а дальше мы все вот эти промежуточные значения сохраняем и дальше переиспользуем, когда считаем градиенты обратно. Вот здесь уже как бы возникает DA, это уже градиент. И считаете градиенты, и на основе всего этого получается градиенты по параметрам. И как только вы получили градиенты по параметрам, делайте обратное распространение ошибки. И так вот много-много раз вы делаете, пока вам этого не хватит. Вот, теперь возникает вопрос. Вопрос следующий сейчас. Кстати, обратите внимание, что здесь еще функция активации на весь слой, а здесь сегмойда, это уже выходной слой. Там, допустим, если у вас бинарная классификация, делаете сегмойду и получаете выходное значение от 0 до 1. Дальше считаете функцию, дальше отсюда попалась функция. Короче говоря, то, что я рассказал. А теперь возникает вопрос. Да, вот здесь, кстати говоря, отвечаю на ваш вопрос. Обратите внимание, что вы считаете, допустим, какой-то... То есть здесь приведена формула в целом для тех нейронных сетей, которые мы рассматривали. При этом функция активации здесь бинарный логлос. Да, бинарный логлос. И, короче говоря, здесь вы видите, что, например, чтобы считать производную d, v, l, здесь используется значение a, l. И получается, мы получаем как раз, когда идем слева направо. Но я просто не стал вводить эту формулу, потому что это... То есть их можно без проблем вывести, я просто вам целый механизм объяснил. Но проследить, как это происходит, полезно. Обратите внимание, что здесь везде матричная операция, потому что у вас там много весов, много параметров. И для каждого нейрона это расписывать не имеет смысла. Поэтому матричная операция. То есть, еще раз, получается слева это forward, справа это backward. А теперь я вот что хотел вам еще рассказать. Сейчас, ребята, я найду это место. Где-то я его только что видел. Вот он. Теперь вопрос, собственно, вот с этим. Вопрос, как веса ты инициализируешь. Потому что у вас должно быть некое начальное значение весов. У вас какое-то определенное. Как вообще, еще раз, у вас есть нейронка, изначально она необычная. Это означает, что у нее есть какие-то веса. Но эти веса, вы их должны как-то задать, значение этих весов. И получается, что есть некие эвристики, как это лучше сделать. Я вам сейчас расскажу, как лучше не делать. Можно просто взять и все задать нулями. Но вот здесь на примере совсем простейшей нейронки показывается, что так делать не очень хорошо. Потому что у вас там на выходе получаются какие-то симметричные градиенты. И тут просто берется напрямую, считается, дальше берутся градиенты. И покажется, что градиенты у вас будут вот такого вида. То есть такие симметричные градиенты. И это не очень хорошо с точки зрения обучения получается. Помимо этого, если вы зададите нулями все, у вас может возникнуть риск того, что выходные значения будут принимать маленькие значения. И у вас может возникнуть вот эта проблема затухания градиента. Кстати, откуда возникает проблема затухания градиента? Вот это видно, кстати, вот здесь. Она как раз из-за этого и возникает. Что если каждый из этих градиентов маленький, то вот это произведение будет еще меньше. Слои между слоями не меняются. Не очень понял. Да, можно несколько слоев. Или мы сразу задаем, вот там слои описали. Нет, они меняются. В том-то и дело, что если у вас градиенты нулевые, близкие к нулю, то они не будут обновляться. А если градиенты… Ну да, здесь все это градиенты. И если каждый градиент принимает небольшое значение, то все это произведение тем более будет маленькое. И получается, чем глубже вы будете идти внутрь нейронной сети, тем меньше у вас будет обновления весов. Поэтому для глубоких нейронных сетей есть риск того, что обучение для глубоких слоев будет проходить сложуче для выходных. И тут как раз поэтому нулями задавать не очень хорошо. То есть я вам дальше расскажу про эвристики, но можно, например, сделать таким образом, грубо говоря, задать значения не очень большими, не очень маленькими, а как бы что-то такое между, грубо говоря. Можно, допустим, взять какое-то равномерное распределение случайное, но домножить на 0,1, чтобы оно не было слишком большое. Ну, короче, это такой момент немного эвристический. То есть тут есть некие подходы.