Мы сегодня с вами говорим про нейронные сети, наконец-то переходим. Начнем с самых простых объектов архитектуры нейронных сетей, то есть это модель перцептрона. Из перцептронов мы будем делать с вами многослойные нейронные сети. Мы с вами говорили про постановку задач машинного обучения с учителем. Я быстренько напомню, что у нас есть данные x и ответ к ним y. Это пример с квартирами, что у нас каждый врага это некий объект квартиры, у каждой квартиры есть некие признаки и есть ответы, это цена. И, допустим, нам нужно предсказать цену. То есть у нас есть x, у каждого x при этом есть признаки x1, x2, x3 и так далее, и есть y. И, соответственно, задачи машинного обучения строятся вот таким образом. Нам нужно подобрать алгоритм A таким образом, чтобы получать отображение из x к y. При этом мы понимаем, что невозможно на всех данных сделать абсолютно точное отображение, поэтому мы вводим loss функцию, которая нам показывает, насколько близко мы приближаемся к ответам. То есть это функция ошибки. И задача сводится к тому, что нам нужно минимизировать эту функцию ошибки. И делаем это мы, меняя вот эти параметры модели. Сейчас я посмотрю, видно. Мы с вами успели поговорить про линейные модели. Опять же, кратко повторюсь, что формула для линейной модели выглядит таким образом. То есть это матричная запись. Я напоминаю, что мы пользуемся матричными операциями, и вы сегодня увидите, почему именно ими. Получается, что loss функция для задачи регрессии – это MSE и Maya. Мы с вами говорили, как они выглядят, что они делают, и как это делается. Мы делаем градиентный спуск. Чтобы посчитать градиентный спуск, нам нужно посчитать градиент. И мы обсуждали, что линейный регрессион выглядит вот таким образом. Правда, транспонирование у нас было вот здесь. Но это зависит от того, как вы задаете матрицы x, y и так далее. Это не важно, просто зависит от того, как вы задаете матрицы. Но в целом формула выглядит вот таким образом. И говорили с вами про задачу классификации. В частности, бинарной классификации. И говорили, что в классификации немножко по-другому выглядит задача. Нам нужно вот эту прямую выделить, которая разделяет объект на два класса. И чтобы это сделать, мы вводим такую функцию sigmoid. На вход этой функции подаем линейную комбинацию. И предсказаниями тогда y будет вот такая функция. То есть на вход этой функции подается линейная комбинация x на y. То есть у нас появляется промежуточная переменная z, которая является линейной комбинацией. И классфункция для логистической регрессии выглядит вот таким образом. Здесь у нас по благорифмуме вот эти самые предсказания. При этом кто-то мне напомнит, какие значения эти предсказания принимают в таком виде, которые после sigmoid. Сигмойд выглядит таким образом. Она стремится к нулю, стремится к единичке. И получается, что от нуля до единицы. И поэтому вот здесь будут значения от нуля до единицы. Здесь один минус. А вот здесь стоят либо ноль, либо один. Соответственно, если ноль, то вот это обнуляется. И остается вот это. Если y равен 1, то вот это обнуляется. И остается только вот это. Во всех классфункциях я напомню, что мы усредняем по всем объектам из датасета. То есть везде стоит сумма по всем объектам из датасета. Это то, что было в прошлый раз. И мы отталкивались от этого. Теперь будем строить с вами нейронные сети. Давайте сначала я вам расскажу, откуда вообще растут ноги. Почему нейронные сети стали вот так популярны. На самом деле вы увидите, что первые модели нейронных сетей были еще в 20 веке. Но они были в основном теоретические. То есть не было достаточно железа, вычислителей. Чтобы нейронные сети обучать, нужны данные и вычислители, чтобы их обучать. Нужно где-то хранить эти данные и их обучать. Поэтому даже в 90-х, когда компьютеры уже развивались и стали напоминать то, что мы сейчас видим, все равно была проблема именно с хранением данных. Вы помните эти дискеты, которые несколько мегабайт можно было хранить. Это еще в 90-х было. Я застал в это время. А вот уже начиная с нулевых, это стало развиваться и появились видеокарточки. Вот тут как раз там, где искусственный интеллект нашел хайп, это обучение нейронных сетей для распознавания образов на изображении. Это сетка AlexNet. Эта сетка, в чем прикол. Раньше применяли классические алгоритмы компьютерного зрения, чтобы решать эти задачи. А тут взяли просто нейронку, обучили, и она кратно превосходила по метрикам классические подходы. И вот тут люди поняли, что когда у вас есть много данных, чем больше вы подаете данных, тем у вас качество нейронных сетей все больше и больше растет. А у классических алгоритмов машинного обучения, которые вы будете проходить в следующем семестре, их качество выходит на некое плато. И, соответственно, получается, мы даже сейчас это видим, то есть какой-нибудь OpenAI берет еще жирнее модели, еще больше данных, и у них качество все растет и растет. Так они уже весь интернет продаются. Ну, короче, они продолжают этот подход. Он заморгал. А что с ним, он перегревается просто? Понятно. Но пока вас не было, только видели. Блин, ну что делать? Я могу, в принципе, просто развернуть монитор. Давайте я договорю мысли. В общем, суть в том, что на нейронке они в этом плане, у них меньше ограничений по качеству, вы на них можете подавать больше данных, и их качество будет все лучше и лучше. И, собственно, когда в нулевые годы появились видеокарточки, и стало возможным хранить много данных, тут вот нейронки хайпанули, и весь этот хайп пошел, по сути, начиная с нулевых 2010-го, По-моему, в прошлом году было 25 лет, когда они появились. Ну вот, это сейчас, скажу, получается какой год-то. 1998-го, да. Знаете что, я вам даже покажу видос. Сейчас, подойдите, перейдите. То есть нейронки, это явно DeepLearn. Еще раз вопрос. То есть сами нейронки, это именно DeepLearn, или еще какие-то? Ну, в основном, да, я имею в виду DeepLearn. То есть, стоит посоветовать машин, которые нейронки? Ну, потому что, давайте так. В принципе, алгоритмы линейной регрессии, они, известно, очень давно и давно использовались. На самом деле, весь этот хайп про Data Science и так далее, я приводил даже личный пример. Я, по-моему, рассказывал, что я когда учился в университете, у меня магистрская диссертация была посвящена задачке, которая связана была с обработкой данных на большом адронном коллайдере. И там повсеместно применяются эти статистические подходы для обработки данных. И оказывается, это Data Science и Machine Learning. Но эти подходы, мне кажется, были, грубо говоря, известны давно, и их применяли гораздо раньше, чем нейронки. Нейронки стало возможным применять именно из-за того, что возник возможность их обучать и хранить много данных. Данные стало возможным тоже хранить чуть раньше, а именно применять видеокарты, чтобы их обучать, стало возможным относительно недавно. Поэтому, собственно, они вот так стрельнули в последнее время, и это все только набирает обороты. Собственно, тут я сразу скажу, у меня слайды немножко недоделаны, потому что мы в процессе того, что делаем курс. Но я буду иногда переключаться сюда. Кстати говоря, вот эти материалы, это курс на Курсере, но можно на Ютубе найти видеозаписи выложенного. Я очень много подчеркнул отсюда. Так вот, в чем проблема линейных моделей, кто мне скажет? Предсказание линейной зависимости. Когда у вас возникает нелинейная зависимость, у вас линейная модель не очень хорошо работает. Вот тут пример, например, нелинейность. Тут зависимость цены от размера, и видно, что здесь 0,0,0,0, а потом с какого-то момента начинает расти. Тут возникает нелинейность, и получается, что ваша линейная модель, наверное, можно построить, но вот здесь возникает нелинейность. Здесь приводится пример, что у вас есть разные фичи, и вы их можете подавать независимо друг от друга на кодек, и они дальше могут идти в такие штуки. Но это мы сейчас отдельно с вами поговорим, поэтому сейчас не буду на этом останавливаться. Про обучение с учителем я говорил, то есть с какими данными можно применять нейронные сети. То есть это табличные данные, аудио, картинки, тексты. Это вы и так знаете, поэтому это мы быстро пропустим. Вот та самая картинка, которую я показывал. Кто не видит, здесь традиционного алгоритма, здесь какие-то нейронные сети, а и тут размеры нейронных сетей. Это маленькие, средние, большие архитектуры, и видно, как у них меняется качество в зависимости от количества данных, которые вы туда подаете. Собственно говоря, здесь показано, как выглядит работа в Deep Learning. То есть у вас появляется идея, вы ее забиваете в код, проводите эксперимент, получается обратную связь, и у вас возникает на основе этого новая идея. То есть это довольно практичная область, во многом экспериментальная. Давайте перейдем к логистической регрессии. Проблема линейных моделей в том, что как только у вас возникает нелинейность, здесь писать нельзя. Вы можете отпустить. Круппу говоря, представьте, что у вас задача классификации. Задача классификации выглядит вот таким образом. Вот у вас христики. Сейчас придумать бы еще. Нолики. Это я в признаковом пространстве. Я придумал как. Смотрите. Вот так вот нолики вокруг этой штуки. А тут внутри христики. Получается, что поверхность, которую я бы хорошо разделял, выглядит таким образом. И тут вы никак линейно это не сделаете. Поэтому линейная модель тут плохое качество. Поэтому, собственно говоря, нужно придумать новые инструменты. В следующем семестре вы пройдете такие алгоритмы, как метод влияющих соседей, градиентный бустинг, случайный лестник, который я говорил. Но они там тоже довольно специфичные. То есть вы увидите, что довольно специфичным образом линейные зависимости приближают. В этом плане нейронки, если их хорошо обучить и так далее, они более точно могут это сделать. Какая тут есть штука с этим связанная? Есть такая теорема, она чисто математическая. И суть ее заключается в том, что если у нас есть какая-то функция, и с какой точностью ее нужно приблизить, мы всегда с этим справимся. Даже однослойной нейронной сетью. То есть мы сможем подобрать такую нейронку веса, что она любую нелинейную зависимость аппроксимирует. Вы уже здесь можете видеть, что такое нейронная сеть. У нас есть входной слой, промежуточный слой и выходной слой. И тут видно, что этот сигнал идет в каждый нейрон. Этот сигнал тоже идет в каждый нейрон, поэтому тут много связи получается. Чисто математически было доказано, что если у нас есть какая-то функция абстрактная, мы можем ее аппроксимировать однослойной нейронной сетью. Теперь давайте посмотрим, что такое нейронная сеть. Я вам показал, как выглядит сетка из нейронов, а что зашито в этот фиолетовый кружочек. Фиолетовый кружочек саши – это такая штука. Что здесь происходит? У нас на обход идут какие-то сигналы. Сигналы – это наши данные, это признаки. В случае с квартирой – это размер, район. Цена метра? Нет, цена – это был таргет. Это то, что мы представили. Это то, что здесь у нас было. А здесь внутри. И это входные сигналы. Они на вход идут с какими-то весами. В1, В2 и так далее. И еще есть у нас по-прежнему сдвиг, В0 некий. Это все суммирует. Модель перцептрона состоит из двух частей. Первая часть – это мы все сигналы суммируем и делаем это линейным образом. Значит, вес – это приоритет? Вес – это как линейная модель, мы взвешиваем сигналы. В этом плане это совпадает с линейной моделью. А вот дальше ключевой момент – это то, что мы применяем нелинейность. Это называется функция активации. Функция активации – это какая-то нелинейная функция. Мы сейчас с вами посмотрим, какие бывают. Суть в том, что именно эта нелинейность позволяет нам аппроксимировать нелинейные зависимости. Давайте теперь посмотрим, какие функции активации бывают. Мы с вами уже видели, что в логистической регрессии применяется сигнуид. Но на самом деле есть разные функции активации. Есть гиперболический тангенс, который от минус одного к одному стремится. Есть вот такая функция, называется… А что ж ты тут делаешь? Он, мне кажется, перегревается просто. Ладно, пока он думает, давайте уж как-то… Я могу просто разворачивать вот это. Ну, давайте я быстро тогда… Пусть так будет. Вам видно, нет? Короче, если что, поближе подходите пока. В общем, у нас функция активации, которая называется relu. Ее суть в том, что при отрицательных значениях она ровно 0, а при положительных, собственно, равна просто x. То есть это прямая под 45 градусов. Мы с вами обсуждали, что тут есть две проблемы. Во-первых, в нуле вот такой излом. И теоретически там может быть проблема со взятием производных. Но мы с вами обсудили, что на практике обычно этой проблемы не бывает. Тут проблема еще в том, что у вас при отрицательных значениях нулевые значения. И получается, что вы, по сути, много сигналов просто обрубаете. Потому что если они на вход нейрона идут отрицательные, то вы их просто обнуляете. И иногда, если вам хочется, чтобы их не обнулять, то можно применить ли кириллу, так называемый. То есть это, когда у вас не ноль, а другая прямая под другим углом. То есть у вас, получается, меньше нуля – это какой-то один угол, а больше нуля – другой угол. Ну и есть всякие разные. Есть елу. Короче, их довольно много придумали. Но самые основные, которые не ровно применяются – это рилу, сигмойда. Я вам уже рассказывал, какие там могут быть проблемы. Я сегодня еще повторю. Гиперболический тангенс бывает. В принципе, любой из них можно применять и смотреть, что у вас получается. Сейчас я попробую переспустить. Пока она думает. Собственно говоря, мы с вами сейчас структуру нейронов посмотрим. Но я давайте все-таки выведем сейчас. Мы с вами обсудим, как сигнал распространяется в нейронных сетях. Давайте пока он думает. Такой вопрос на засыпку. А что будет, если у нас не будет функции активации? То есть если мы просто суммируем все сигналы… Давайте вот такой вопрос на засыпку. Что будет, если мы просто уберем из перцептрона функцию активации? Отсюда вот этого вообще уберем. Оставим только вот это. Будет просто линейная функция. Даже если у вас будет много каких-то нейронов, но вы всех уберете функцию активации, у вас просто все линейные комбинации друг к другу будут складываться и останутся линейные комбинации. Это к тому, что функция активация – это ключевая вещь, которая нам позволяет делать аппроксимацию нелинейных зависимостей. Обучение. Сейчас я вот тут буду щелкать иногда другим материалом. Давайте посмотрим. Это мы с вами уже проходили. Рассказываю четко. Соответственно, логистическая регрессия, как она выглядела еще раз, что у нас есть линейная комбинация, но мы берем сигнольду и дальше применяем такую функцию. В случае нейронной сети у нас получается, что мы можем взять много нейронов. То есть если в логистической регрессии у нас было только одно место, куда стекались все… Я хотел сравнение с логистической регрессией, как это выглядит. Представьте, что в логистической регрессии у нас получается, что по-прежнему красный входной сигнал стекается в одно место, и у вас output layer. Получается, что в логистической регрессии у вас не будет вот этого, и в фиолетовых будет только один кружочек. То есть вот в этом разница получается. А в многослойных нейронных сетях у вас может быть несколько слоев и много нейронов в каждом слое. То есть еще раз, давайте, знаете, как сделаем. Вот так вот сделаю. И получается, да, вот картинка внизу. Видите, получается, что здесь все стекается в одно место, и там применяется сигмой. А здесь, видите, у нас получается много связей, много нейронов, много слоев. В данном случае два слоя. Вот в этом отличие. Продолжаем здесь. Да, может быть на самом деле много выходов. Вот придумайте задачу, где может быть много выходов. Давайте, кто может предлагать? Есть решение? Несколько выходов, да, то есть у нас output var, noval. Классификация? Да. Может быть, например, самая простой, наверное, компьютер вижн, который предъявляет кофе, собачку? Да, то есть вот есть датасет, который называется ImageNet. Там тысяча классов и, соответственно, тысяча вот таких выходных нейронов. Ну, не нейронов, а выходов. Теперь давайте с вами рассмотрим прямое распространение. Сейчас нужно будет немножко напрячься, понимая, что уже конец дня и сложно. Но давайте верхний уровень посмотрим, как это выглядит. То есть у нас, получается, есть... Ну, будем на таком участке нейронной сети смотреть. То есть мы сейчас не будем всю нейронку смотреть, а просто участок. То есть вот у нас есть, грубо говоря, некий слой. Мы его назвали Admin. ht-1 и ht — это выходной слой. И вот нам нужно посчитать, какие же будут выходы на основе значений, которые находятся здесь. И если абстрактно, то получается, что вот у нас есть вот эта самая функция активации, есть какие-то веса, V большое. Мы, значит, эти веса домножаем на значения из вот этого нейрона, из этого слоя, точнее, и прибавляем еще некий V. Давайте теперь подробнее рассмотрим, а что там лежит. Потому что обратите внимание, что у нас здесь V большое. То есть это некая матрица с весами получается. И, собственно говоря, на всякие эти подписи не обращайте внимания, а сравнение, что было и что стало. То есть было вот так вот. То есть это просто линейная модель. Линейная модель — это мы наши веса домножаем на признаки. То есть это получается матричное произведение в строке на столбец. А теперь обратите внимание, что у нас здесь происходит. Здесь у нас появляется матрица V. Откуда она появляется? Она как раз появляется оттуда, что у нас теперь тут много нейронов, и у каждого нейрона будут свои связи с этим слоем. То есть, грубо говоря, вот здесь вот раз, два, три, четыре, пять, шесть. Вот, например, у этого нейрона будет V1, V2, V3, V4. У этого нейрона будет V1, V2, V3, V4. И так вот шесть раз. И получается, если вы сюда посмотрите, то здесь как раз оно и есть. Ну, тут зависимость от того, как вы для себя решите, но давайте так. Количество строк пусть будет количество нейронов, а количество столбцов — это пусть будет количество связей со следующим слоем. То есть, вот представьте, что V1,V1,V1,2,V1,3,V1,4 — это будут веса вот эти вот. То есть V1,V1,V1,2,V1,3,V1,4. И то же самое будет для этого нейрона, только у него будет V2, V2, V3, V4 и так далее. То есть вот здесь уже видна разница между нейронкой и просто линейной моделью. Но как бы следует обратить внимание, что если вы каждую строку по отдельности будете умножать на эту штуку, у вас по отдельности будет вот это, просто много раз вы это делаете. То есть получается, что… Поэтому я как бы и начинал с линейных моделей, потому что на основе линейных моделей базируется построение нейронных сутей. И, собственно говоря, здесь это и показано, что чтобы получить вот этот синий квадратик, вам нужно строчку перемножить на столбец. А зеленая, да, это будет вот эту строчку умножать на этот же столбец. Ну, на вектор с вечами. То есть за каждую строку мы умножаем в атмосфере? Да, то есть получается, что у вас вот здесь на самом деле над каждой этой линией есть какой-то вес, по сути. И вы видите, что их получается много, поэтому и получается, что вам это удобнее в виде матриц выписывать. Вот почему я делал акцент на том, что в нейронках очень нужна матричная операция, потому что вот такие операции, они много-много раз выполняются для разных связей. И вы их можете сгруппировать с помощью матричных операций. Нейрон может передавать дальше, но всегда один и тот же вес передает, или он разный может передавать? Если один... Там ставят симпатику. Верхний нейрон слева, он правый нейрон и разные веса передает? Да, да. Получается, на выходном слой у вас было четыре красных кружочка, в каждой кружочке будут другие веса разные. И эти веса будут подбираться в процессе обучения. Я сейчас вам покажу немножко другую иллюстрацию того, что я сейчас рассказал, немножко более сложную, но как бы там прям подробно. Я поэтому призываю... Уже опять про это все. Да, да, я знаю. Сейчас пока он будет думать, я вам сейчас открою. Пока, кстати, открываю. Расскажите, вот как семинар прошел? Клево было? Я так посмотрел, вроде прикольно там все. Егор сделал хорошее задание. Так, ну ладно, я сейчас приду в следующий раз. Давайте пока запускайте, может, вопросы. Всем вам понятно, в чем фишка? В том виде, да, здесь есть слаймер. Это просто число. То есть каждый нейрон, к нему на вход приходит много чисел, они как-то агрегируются, и через функцию активации уже выходит одно число. У тебя когда-то задался вопросом, почему нужно эти слои, почему нельзя создать обходного бронированного эффекта. Но мы хорошо понимаем, что функция активации. Это, кстати, уже другой материал немножко, но, короче, я к чему. Вот здесь тоже показано, что у нас есть некий входной слой, скрытый выходной. И здесь показано, что вот здесь вот В1, В1. То есть получается В1 это матрица 4 на 3. То есть вот в квадратных скобках 1 это означает, что на весь слой веса будет матрица 4 на 3. Почему 4 на 3? Потому что 4 нейрона и 3 входных сигнала. То есть у каждого нейрона получается по 3 веса, и таких нейронов 4. Поэтому 4 на 3. И вот здесь подробно расписывается, я просто быстро вам покажу, чтобы вы видели. То есть для каждого нейрона получается вот такая вот запись. То есть опять два этапа. Линейная комбинация и не линейная. И в итоге эта матрица выглядит вот таким образом. Тут он просто не стал расписывать, что 3 значения. Но суть в том, что каждая строка для каждого нейрона отличается при веса. То есть здесь получается 3 столбца и 4 строки. И получается каждая строка это веса соответствующего нейрона. 1, 2, 3, 4. То есть у вас получается матрица весов. В итоге вы один большой. И обратите внимание, что на выходе из каждого нейрона свой сдвиг. Потому что если вы помните линейную модель, там один сдвиг на всю модель. А так как у нас здесь много нейронов и каждая нейрона это модель сама по себе простая, то у каждого выхода еще свой сдвиг. Вот такие дела. Это я вам рассказал, как у нас сигнал слева направо распространяется. Итак, возвращаемся к нашим слайдам. Вот эта матричная запись. Итого у нас на самом деле вот то, что здесь изображено. Это вот это. Кто мне сможет сейчас указкой расшифровать, что здесь происходит. Кто-то может подойти и с указкой мне рассказать, что угадать, расшифровать эту запись. Ну или можете говорить, я буду... Ну да, а это соответственно да. Это вот то, что здесь будет. Четыре числа будут. Ну, заточнее, стоп, не четыре числа. Сейчас скажу стоп, стоп. Получается... Давайте я попробую. Да, давай. Твоя функция, по сути, активировалась. А сейчас... да, давай. Ну, здесь вот 0, это вес первого картины, а f 0, это уже сам первый нейрон. Ну вот, я и сниму. А, да. То есть вот этот нейрон делает эту функцию. Так. Вот. Получается, v1, это скорее всего... Ну, v1, да. А почему v1? Ну, получается, на вход, наверное... А, хм. А, понятно. Наверное, вес, вот этот нейрон добавляет вес, но почему он v1? Понятно. Может быть, потому что он переходит в этот нейрон? Не, ну, в плане, почему v1, это... Ну, давайте сейчас, во-первых... Во-первых, х это вот это желтое, да? Это все в целом... Да, х это все желтые значения. Х, это х. Значит, дальше этот х с какими-то весами b0, обратите внимание, b0 plus означает, что b0 закрыта все веса, которые здесь на этими линиями, да? Плюс некий b0, тут тоже закрыта вся вибрация. То есть это матричная запись, получается, и f0, да, это некая функция активации, применяется здесь, вот, и получается, что на выходе вот из этого, на выходе из этого мы получаем значение для этого слоя, для слоя 1. Дальше, соответственно, мы используем значение этого слоя, чтобы получить значение для этого слоя. И поэтому получается, что для того, чтобы посчитать значение этого слоя, мы значение вот этого слоя теперь умножаем на матрицу v1, и получается, что v1 закрыта все веса, которые здесь. И получается, как мы применяем f1, получаем значение здесь. Теперь дальше, вот чтобы получить значение для этого слоя, мы значение, которое получили здесь, умножаем на v2, то есть v2 закрыта все веса, и получаем, соответственно, значение здесь. То есть это получается здесь, в итоге мы получаем то, что здесь. Ну и, наконец, мы умножаем на v3 выходы из этого слоя, и получаем конечное значение. То есть получается, что v3 зашифровал все вот эти нейроны, которые здесь. И получается, в итоге, что если вот это все сделать, мы получаем выходные значения. Теперь обратите внимание, что это математическая запись. Я почему хотел подробно вам это рассказать, потому что получается, что, например, чтобы получить значение скрытого слоя 2, вам нужны значения скрытого слоя 1, которые, в свою очередь, получаются из значений вторных. То есть это как такой матрешка. Чем дальше идем, тем более запись вырастает. Но в корне этой записи лежит простая вещь. Вы просто используете значение предыдущего слоя, а, в свою очередь, чтобы посчитать этот слой, вы используете его значение еще более предыдущего слоя. В итоге получается, что, чтобы получить значение на выходе, у вас используются все вот эти связи, все слои и так далее. Ф получается функция активации? Да, везде это функция активации. Здесь это может быть на выходе. Я вам расскажу, что здесь может быть на выходе. То есть, на самом деле, если F0, F1, F2 это может быть Reul, то для F3 можно применить Softmax. А почему мы используем матрицу? То есть четыре значения, они дальше используются для расширения функции. Но вы можете просто взять какое-то конвертное значение и соответственно... То есть, например, на выходе самое простое, что можно взять, это смотреть самый большой вес. Ну, смотрите, то, о чем поговорили, это только вы смотрите значение, которое здесь, и наибольшее значение будет соответствовать индексу класса, который предсказывает нейронку. Но это вы на семинаре увидите. Короче говоря, да, это правильно то, что вы говорите. Поэтому, опять же, в плане, что на выходе получится, зависит от того, что у вас будет в качестве V3 и так далее. То есть, если у V3 размерность будет на выходе 4, то вы получите четыре значения. Правильно вообще? Ну да, да, правильно. Окей, и таким образом, давайте я опять разверну, вот это будет своя матрица весов. Ну, функция активации, это зависит от того, как вы зададите. Обычно в рамках одного слоя задают одну и ту же функцию активации. Но для разных слоев можно разные принципы. Для каждой значения? Для каждой перевалов подачи? Не, ну можно, но обычно так не делают. Почему так не делают? Потому что вам нужно будет делать обратное распространение ошибки. И чем сложнее вы это будете задавать, тем сложнее будет считать эти градиенты. То есть обычно все, кто пытается в этом плане не слишком переусердствовать. То есть по-хорошему на картинке между слоями надо нарисовать еще функцию активации? Ну да, тут и везде зашита функция активации. На выходе из каждого слоя вот здесь, грубо говоря, есть нелинейность этого слоя. То есть это матричная запись так называемого инференса. Что такое инференс? У вас есть на входе иксы, и вы их распространяете, чтобы получить выходные значения. То есть это распространение сигнала слева направо. Представьте, что вы уже нейронку обучили. Если на вход приходит икс, чтобы получить выходные значения, вам нужно совершить математические операции. Поэтому работа нейронок – это просто перемножение матриц между собой с математической точки зрения. А теперь давайте посмотрим, как их теперь обучать. Только вот мне, чтобы это вам рассказать. Да, вот сейчас получилось. Сейчас оно вернется. Если вопросы есть в чате, тоже задавайте. Сейчас я проверю, у нас все идет. Напишите там плюс всего нормального в чате. Да, все плюс. Спасибо. Сейчас проект отключится, и я продолжу. А теперь мы с вами будем говорить про обучение. Напомните, как мы уже умеем обучать модели машинного обучения. Какой мы метод с вами рассмотрели. То есть что нужно сделать, чтобы обучать модель машинного обучения. Камон, я в начале лекции что-то говорил. Ну, если вы подавали часа... Ну, веса, да. Вот как веса пропустить. Ну, нужны данные и результаты ответов. Так, и дальше что мы делаем? Вот у нас есть ответы, да, и есть выходы модели. Что с этим можно сказать? Считать ошибки. Дальше считаем ошибки. А как мы не без этого? Я это все почему? Потому что для нейронов остается все то же самое абсолютно. Уже знакомая вам формула. Мы для каждого веса. Представьте, у вас получается над каждой линией у вас есть свой какой-то вес. И вот для каждого веса вам нужно совершить такую операцию. И как вы видите, чтобы ее совершить, вам нужно посчитать производную. Причем много производной. И как вы можете понять, чем дальше у вас идет вглубь нейронки, тем больше надо сделать вычислений. Это логично. Потому что, как я вам говорил, смотрите, можно вернуться в эту запись. Чтобы посчитать производную по V0, вам нужно, видите, сколько здесь внешних оболочек. То есть получается 1, 2, 3. То есть вам нужно как минимум начать снаружи и внутрь вот так вот считать. И получается, что аналитически это делается не очень здорово. Особенно когда у вас глубокая нейронная сеть. Просто в лоб считать производную не очень здорово. Поэтому придумали такой лайфхак математический. Я про него говорил прямо на первой лекции. Он лежит в основе нейронных сетей. В частности, Джефф Дейхинтон, который получил в этом году за физику, он этот метод разработал. В чем заключается суть? Суть заключается в том, что мы сначала строим граф вычислений. Это просто некая иллюстрация абстрактная. Это не связано с этой картинкой. Это просто некая математическая абстракция, чтобы вам объяснить, в чем заключается метод. Представьте, что вы хотите обновить вот эти веса. При этом вычислительный граф. Представьте, что у вас какая-то абстрактная математическая функция. Чтобы получить выход, у вас есть две... Короче говоря, давайте я дальше сейчас... Что здесь нарисовать буду? Представьте, что получается у равно x1v1, и на это навешивается сигнал 1. В свою очередь сюда еще приходит сигнал отсюда, а сюда приходит сигнал и от x1, и от x2. И они все, короче, агрегируются здесь, и дальше мы получаем некий выход. Так вот, чтобы посчитать производное, можно воспользоваться лайфхаком. Мы вводим такие промежуточные перемены. Здесь, допустим, у1, у2. И чтобы посчитать производное по у1, вам нужно отследить от выхода. Теперь мы двигаемся справа налево. Нам нужно отследить, каким путем нам нужно пройти, чтобы добраться сюда. Мы видим, что мы идем справа налево. И вот по этому пути мы сюда набираемся. Теперь мы смотрим, какие у нас функции стоят на пути. Мы видим, что у нас возникла сигмойда, значит у нас будет производная dl по dсигмойда. Дальше мы берем производную сигмойда по у, потому что мы уже здесь, и нам сюда нужно. Теперь отсюда сюда. Это просто получается dy по dсигмойд. И, наконец, последняя производная получается dсигмойд по dy у1. И получается, чтобы посчитать вот эту производную, которая… Обратите внимание, наша задача – посчитать производную вот этой итоговой функции у1. И получается, что она, согласно методу взятия производных сложных функций, равна произведению всех этих производных. Получается, чтобы нам посчитать производную отсюда выходной функции по dсигмойд, нам нужно построить вычислительный граф, посмотреть путь распространения сигнала назад и взять все частные производные, которые у нас окажутся на пути, и перемножить их. На самом деле можно было бы просто напрямую считать вот эту штуку. Но я потом приведу пример. Можно взять какую-то функцию, например, ту же сигмойду, и брать напрямую производную. Но это практика показывает, что когда у вас сложные функции, это сделать гораздо сложнее, чем если вы разбиваете на вот такие функции. Потому что, как правило, такие производные по отдельности гораздо проще. И, собственно говоря, получается, что метод заключается в том, что вы берете… выходную функцию и считаете вот эти все производные, которые у вас окажутся на пути, и получается в итоге делать вот такие операции. То есть, как вы можете понять, мы хотели по v1 считать, то есть по v1 у вас просто добавляется множитель du1 по dv1. Вот, финальный пункт, вот здесь еще один множитель. И все, получается dn по dv1 будет все то же самое, только вы здесь добавляете еще один множитель. Вот такой метод называется chain rule или метод обратного распространения ошибки. Получается, что, еще раз, так выглядит обучение нейронов. Получается, сначала вам нужно посчитать слоз функции, а чтобы посчитать слоз функции, вам нужно распространить сигнал слева направо. И получается, что вы сначала высчитываете выходной сигнал, для этого слева направо двигаетесь. Вот вы, как только получили выходной сигнал, можете посчитать слоз функцию. И как только вы посчитали слоз функцию, вы теперь обратно двигаетесь и берете все производные на пути и просто начинаете их перемножать. И как только у вас какой-то градиент появился, вы его применяете для метода градиентного спуска. То есть вы для каждого слоя можете делать свой градиентный спуск. Как только у вас появился градиент, вы сразу можете применить градиентный спуск. Получается, в этом и заключается метод. Он называется backpropagation. Почему backpropagation? Это буквально обратное распространение ошибки называется метод. Потому что вы считаете ошибку, и вы буквально справа налево занимаетесь вычислениями. То есть сигнал как будто справа налево обратно идет. Но не идет, а вы считаете все эти производные. Я вам сейчас покажу, как это можно еще раз смотреть. Я еще раз повторяю, что в этой лекции супер подробно. Я многие вещи сейчас опустил. Но тем не менее. Здесь как бы немножко сложно, поэтому я не буду. Смотрите, вот эта схемка. Давайте так. Зачем нам нужно слева направо распространять сигнал? Чтобы обучать нейронке, нам нужно сначала сделать forward, а потом backward. Вот здесь видно, зачем нам нужно делать forward. Помимо того, что нам нужно выходной сигнал считать, нам нужно еще в процессе понять, а в каких местах нам считать производные. Нам нужны все промежуточные значения. Давайте я попробую примерить рано. Грубо говоря, получается вот здесь выходной сигнал. А вы можете здесь увидеть, здесь написано cache и все промежуточные значения. Мы, грубо говоря, еще параллельно храним все выходные значения слоев и так далее. Почему мы это делаем? Потому что они используются, когда мы будем делать обратное распространение ошибки. Получается, что в любом случае при обучении нейронок вы много раз делаете одно и то же. Берете сигнал, распространяете слева направо, запомнили все промежуточные значения, посчитали loss функцию и дальше начинаете считать производные в обратном порядке справа налево. Таким образом вы посчитали все градиенты, сделали градиентный спуск. Теперь снова вы слева направо двигаетесь, считаете все значения. У вас нейронка же обновилась, когда вы веса поменяли. И вы с обновленными весами снова сделали forward propagation, backward propagation. Снова у вас веса поменялись. И так итеративно вы делаете до тех пор, пока функция ошибки не примет удовлетворительное значение для всей нейронки. Понятно ли в целом механизм, как нейронка обучается? Давайте вопросы, потому что это довольно непросто. Какие у вас вопросы? Так, пока включу проектор. Если в чате тоже есть вопросы, пишите. И сейчас я вам буквально пару моментов еще уточню. Давайте вопросы еще. А вот вы просто, это, кстати, хорошее упражнение. Возьмите, нарисуйте какой-нибудь простенький нейрон, например, 5 парных сигналов. И промежуточный слой не делайте сильно большим, просто несколько нейронов. Допустим, даже можно один слой промежуточный сделать и какой-то выходной слой. И попробуйте честно посчитать производную. Если вы будете делать по тому механизму, который я объяснил, по методу chain rule, то есть обратного распространения ошибки, и цепочкой считать производную, вы увидите, чтобы их считать, вам нужно было выйти дальше. Просто без них вы не сможете считать предельно. Поэтому вы, как бы, заслабился, грубо говоря, на некий кэш и переиспользуете, когда считаются градиенты. И это как раз вот здесь видно. То есть, грубо говоря, мы справа налево, когда идем вот эти все там веса, какие-то сдвиги и выходные значения, а дальше мы все вот эти промежуточные значения сохраняем и дальше переиспользуем, когда считаем градиенты обратно. Вот здесь уже как бы возникает DA, это уже градиент. И считаете градиенты, и на основе всего этого получается градиенты по параметрам. И как только вы получили градиенты по параметрам, делайте обратное распространение ошибки. И так вот много-много раз вы делаете, пока вам этого не хватит. Вот, теперь возникает вопрос. Вопрос следующий сейчас. Кстати, обратите внимание, что здесь еще функция активации на весь слой, а здесь сегмойда, это уже выходной слой. Там, допустим, если у вас бинарная классификация, делаете сегмойду и получаете выходное значение от 0 до 1. Дальше считаете функцию, дальше отсюда попалась функция. Короче говоря, то, что я рассказал. А теперь возникает вопрос. Да, вот здесь, кстати говоря, отвечаю на ваш вопрос. Обратите внимание, что вы считаете, допустим, какой-то... То есть здесь приведена формула в целом для тех нейронных сетей, которые мы рассматривали. При этом функция активации здесь бинарный логлос. Да, бинарный логлос. И, короче говоря, здесь вы видите, что, например, чтобы считать производную d, v, l, здесь используется значение a, l. И получается, мы получаем как раз, когда идем слева направо. Но я просто не стал вводить эту формулу, потому что это... То есть их можно без проблем вывести, я просто вам целый механизм объяснил. Но проследить, как это происходит, полезно. Обратите внимание, что здесь везде матричная операция, потому что у вас там много весов, много параметров. И для каждого нейрона это расписывать не имеет смысла. Поэтому матричная операция. То есть, еще раз, получается слева это forward, справа это backward. А теперь я вот что хотел вам еще рассказать. Сейчас, ребята, я найду это место. Где-то я его только что видел. Вот он. Теперь вопрос, собственно, вот с этим. Вопрос, как веса ты инициализируешь. Потому что у вас должно быть некое начальное значение весов. У вас какое-то определенное. Как вообще, еще раз, у вас есть нейронка, изначально она необычная. Это означает, что у нее есть какие-то веса. Но эти веса, вы их должны как-то задать, значение этих весов. И получается, что есть некие эвристики, как это лучше сделать. Я вам сейчас расскажу, как лучше не делать. Можно просто взять и все задать нулями. Но вот здесь на примере совсем простейшей нейронки показывается, что так делать не очень хорошо. Потому что у вас там на выходе получаются какие-то симметричные градиенты. И тут просто берется напрямую, считается, дальше берутся градиенты. И покажется, что градиенты у вас будут вот такого вида. То есть такие симметричные градиенты. И это не очень хорошо с точки зрения обучения получается. Помимо этого, если вы зададите нулями все, у вас может возникнуть риск того, что выходные значения будут принимать маленькие значения. И у вас может возникнуть вот эта проблема затухания градиента. Кстати, откуда возникает проблема затухания градиента? Вот это видно, кстати, вот здесь. Она как раз из-за этого и возникает. Что если каждый из этих градиентов маленький, то вот это произведение будет еще меньше. Слои между слоями не меняются. Не очень понял. Да, можно несколько слоев. Или мы сразу задаем, вот там слои описали. Нет, они меняются. В том-то и дело, что если у вас градиенты нулевые, близкие к нулю, то они не будут обновляться. А если градиенты… Ну да, здесь все это градиенты. И если каждый градиент принимает небольшое значение, то все это произведение тем более будет маленькое. И получается, чем глубже вы будете идти внутрь нейронной сети, тем меньше у вас будет обновления весов. Поэтому для глубоких нейронных сетей есть риск того, что обучение для глубоких слоев будет проходить сложуче для выходных. И тут как раз поэтому нулями задавать не очень хорошо. То есть я вам дальше расскажу про эвристики, но можно, например, сделать таким образом, грубо говоря, задать значения не очень большими, не очень маленькими, а как бы что-то такое между, грубо говоря. Можно, допустим, взять какое-то равномерное распределение случайное, но домножить на 0,1, чтобы оно не было слишком большое. Ну, короче, это такой момент немного эвристический. То есть тут есть некие подходы. Но я про них чуть дальше расскажу, просто тут в целом я… А вы же занимаетесь аранномно присваивать? Аранномно присваивать? Ну, как бы здесь да, но вообще есть некие эвристики, как лучше это сделать. И я про это расскажу на следующем занятии, если не забуду. Там есть специальные методы, я вам потом ссылку пришлю, как они называются и как выглядят. Там немножко более сложные эвристики, но в целом есть подходы, как лучше сделать. То есть если взять тот же PyTorch, вы когда там программируете нейронную сеть, там обычно уже на автомате с какими-то весами задается, с теми самыми эвристиками, которые я сейчас говорю, не с этими, а которые есть подходы, просто я про них чуть дальше расскажу. Это первый момент, что у вас результат будет сильно зависеть от того, с каким начальным приближением вы начнете обучать нейронку. И что еще? Тут про что рассказывают? Тут рассказывают про то, что у вас когда много слоев и, допустим, у вас задача какая-то на компьютер визент, то тут глубокая representation. То есть, грубо говоря, в глубоких слоях у вас будут более простые элементы фичи. То есть на выходах из нейрона в более глубоких слоях у вас будут создаваться какие-то совсем простые фичи. И чем ближе к выходу, тем больше у вас выходов будут напоминать уже что-то более осмысленное. Это возникает из-за того, что вы обучаете, и так получается. Есть такая некая штука с нейронкой, что в глубоких слоях у вас более простые фичи задаются, и дальше чем ближе к выходу, тем у вас более что-то осмысленное. Это если не интуитивным образом рассказывать. Есть целая работа, которая изучает как слои нейронных сетей, есть ли в них какой-то смысл. Пытаются изучать как слои что-то физическое создают и так далее. Я видел работу, связанную с LLM. Но фишка в том, что чем больше у вас нейронка, тем сложнее анализировать, потому что у нее куча слоев, куча параметров. Но некая интуиция в этом заключается. Что еще вам рассказать. Вроде я все рассказал. Как обучаются нейронки в целом. Вы сейчас дали именно за эту архитектуру анализ? Не прямо за эту архитектуру, а в целом. За эти линейки? В целом, да. Смотрите, я чуть подробнее расскажу. Там оба этих человека, с которым дали, один Кинтон, а другой Фопкинс. И оба они стояли у истоков. Один из них как раз предложил метод обратного распространения ошибки. Но обоим дали формально за то, что они придумали всякие архитектурки. Причем придумали их на основе физических инсайтов. У них в голове крутилась некая физическая модель. Они ее переложили в виде математики и получили модель Больсмана, и модель Фопкинса. Они ее получили на основе инсайтов из физики. В итоге это стало существенным вкладом в нейронки. Почему именно за физику дали, непонятно. Но считается, что в формальном релизе написано, что они на основе физики вывели свои нейронки. Но сами нейронки стали активно применяться не только в физике, а в разных областях. В общем, если вкратце, то получается такая история. Что я хотел сказать. Давайте последний момент скажу. Если вы захотите запрограммировать это своими руками, понятно, что сейчас есть фреймворки, которые это все делают. Тот же PyTorch автоматически умеет строить самые вычислительные графы и высчитывать производные. Как это делать дальше, Егор на семинарах расскажет. Но, допустим, вы хотите сделать это сами. Чтобы сделать это сами, вам нужно будет применить один лайфхак, про который я сейчас расскажу. Лайфхак заключается в том, что как можно меньше использовать циклы. Потому что это сильно замедляет, во-первых, во-вторых, усложняет. На примере таких простых вещей. Лямбда функции? Не лямбда функции, а простой пример. Было, например, ax плюс b, и b это столбик с числами. Но все числа одни и те же, например, для линейной регрессии. У вас получается, что если b это столбик, а вам нужно 4b, вы можете оставить это просто столбик. Нумбай, например, автоматически из этого сделает столбик. И тогда у вас операция получится. Грубо говоря, получается и здесь дальше такая штука, что когда речь идет о всяких операциях сложения, учитания и так далее, или умножение на число какое-то, то не надо сгородить циклы. В том же Нумбай это все делается автоматически. Или, например, в Sigmoid вы меняете экспоненты от минус x на y. То есть вы можете просто сделать np.x и туда сразу матрицу задать. Он для каждого элемента матрицы применит экспоненты. То есть вам не нужно писать цикл for и в этом цикле писать для каждого элемента экспоненты. Ну, короче, это просто некие лайфхаки. Растить себе жизнь, если вы захотите это делать. Мы как раз к 9 подходим. В принципе, на самом деле у меня особо добавить нечего. То есть я призываю посмотреть материалы, посмотреть отдельно лекции. Но давайте закончим тем, что откуда вообще взялась вот эта тема, что нейронная цель. Типа человеческий нейрон. Там есть некое ядро, в это ядро приходят сигналы. То есть каждый нейрон связан с другим нейроном. И они связаны через такие вот штуки. И приходят сигналы, они в ядре как-то там обрабатываются и уходят дальше. Но это просто какое-то выходное значение. Но суть как бы в том, что надо понимать, что вот это и вот это, это, конечно, не прямая аналогия. Мне кажется, нейробиологи до сих пор может не очень понимать, что вот здесь происходит в ядре реального нейрона человеческого. Но это чисто вот такая математическая абстракция. И просто из-за того, как это похоже выглядит, вот эта картинка, не надо думать, что это прям реальная модель. Вот эта модель. То есть это просто некая математическая абстракция, просто ее назвали нейронной сетью. Потому что тут тоже кажется, что вот этот нейрон связан с предыдущим. Тоже идут какие-то сигналы, какие-то нелинейности. Но надо понимать, что нелинейности, которые в этой модели, они, конечно, уже гораздо проще, чем то, что реально происходит. Это просто некая математическая абстракция, поэтому назвали нейронной сетью. Из этой лекции вам нужно вынести еще раз, по сути, две вещи. Как происходит вот эта вещь. Точнее, три вещи. Во-первых, как выглядит устройство отдельно нейрона. Еще раз. Выглядит это таким образом. Дальше вам нужно вынести, как выглядит распространение сигнала слева направо. И, наконец, вам нужно разобраться, как работает механизм обратного распространения шелки или chain rule. Если вы захотите подробно смотреть те формулы, как это выглядит, то можете смотреть вот эту PDF. Там немножко непонятно, но можно найти в YouTube видеозапись этой лекции. Там, соответственно, это сопровождает. Можно проследить. Мне лично, для понимания, очень помогла эта лекция. Это из курса специализации Deep Learning. Это Deep Learning. Можете прямо загуглить в YouTube. Пока он немножко работает, можете в YouTube пить и прямо эти лекции найти. Что мне лично очень понравилось, что он прямо суперподробно выводит вот эти вещи. Он начинает с логистической регрессии. Это Андрю Анджи. Да, это Андрю Анджи. Он начинает с логистической регрессии и показывает переход к нейронке. Особенно здесь он прямо для каждого нейрона расписывает эти уравнения. Дальше показывает, как это все векторизуется. Причем это показывает векторизацию. Он показывает векторизацию на весь датасет. А я вам показал для одной строчки из датасета. Я вам, по сути, показал векторизацию для одного элемента из датасета. Можно вот эти все вещи для всех элементов из датасета обобщить. Я просто сложно здесь разобраться, поэтому не стал рассказывать, но это тоже можно сделать. И вот здесь он подробно про это говорит. Короче говоря, если вам это будет интересно, посмотрите, потому что вы прям реально разберетесь. Механизм работы нейронных детей вы, посмотрев эту лекцию, разберетесь. Ну а, соответственно, Егор вам будет дальше рассказывать, как это программировать, обучать. И вот так. Вроде я все разобрал. Если что. А ну-ка, Teams, если есть вопросы, давайте. Потому что, в принципе, я рассказал то, что хотел с вами. Общайте плюсы, если все было понятно. Если кто хотел со мной пообщаться, то, пожалуйста, приходите. Спасибо. До свидания. 